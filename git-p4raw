#!/usr/bin/perl

use strict vars, subs;
use warnings;
use Scriptalicious;
use Maptastic;
use FindBin qw($Bin);
use List::Util qw(sum max min);
use Scalar::Util qw(looks_like_number);
use Data::Dumper;
use DBI;
use Cwd;
use IO::Handle;
use File::Path qw(rmtree);
use Fatal qw(:void open);
use Digest::SHA1;
use Digest::MD5 qw(md5_hex);
use Text::Wrap;
$Text::Wrap::columns = 72;
use JSON;
use YAML;
BEGIN { eval "use Term::ProgressBar" };

use vars qw($SHARE $SCRIPT_MODE);
$SHARE = $Bin;

sub do_init {
	my $dbh = shift;
	run("git", "init");
	run("git", "config", "p4raw.source", getcwd);
	$dbh->begin_work;
	say "Setting up tables on DB ".$dbh->{pg_db}." (in a transaction)";
	open SQL, "<$SHARE/tables.sql" or die $!;
	my $statements = join "", <SQL>;
	close SQL;
	mutter "Running: $statements";
	eval {
		local($dbh->{PrintError});
		$dbh->do($statements);
		$dbh->commit;
	};
	if ( $@ ) {
		my $msg = $@;
		chomp($msg);
		$dbh->rollback;
		barf "couldn't set up tables - already setup? ($msg)";
	}
	say "Set up DB OK";
}

sub do_drop {
	my $dbh = shift;
	open SQL, "<$SHARE/tables.sql" or die $!;
	my $statements = join ";\n", reverse
		map { (m{create (table|sequence) (\S+)}
		       ? ("drop $1 $2"
			  . ($1 eq "table" ? " cascade" : ""))
		       : ()) } <SQL>;
	close SQL;
	mutter "Running: $statements";
	$dbh->begin_work;
	$dbh->do("set constraints all deferred");
	$dbh->do($statements);
	$dbh->commit;
	say "Dropped DB OK";
	my $git_dir = capture("git", "rev-parse", "--git-dir");
	my $source = capture("git", "config", "p4raw.source");
	if ( $source ) {
		if ( $source eq getcwd ) {
			rmtree($git_dir);
		}
		else {
			moan("source is '$source', not ".getcwd
			     ."; rm -rf $git_dir yourself");
		}
	}
	else {
		moan "no p4raw.source; not removing no git dir";
	}
}

sub do_load {
	my $dbh = shift;

	my %load_opts;
	{
		@ARGV = @_;
		getopt("r|reload" => \$load_opts{reload},
		       "f|force" => \$load_opts{force},
		      );
		@_ = @ARGV;
	}

	my @files;
	if ( @_ ) {
		@files = @_;
	}
	else {
		@files = grep { -f }
			(<journal checkpoint journal.*.gz checkpoint.*.gz>,
			 <p4raw-extra-*.asv>);
	}

	goto no_filter if $load_opts{force};

	#FIXME: this logic is naff.  The journal of the same number
	#must be imported as well.  Import with -f
	my $already_got = row_iter($dbh, <<'SQL')->();
select
	max(regexp_replace(source_file, E'.*\\.([0-9]*)\\.gz.*', E'\\1'))
from
	(select distinct
		source_file
	from
		change
	where
		source_file ~ '(journal|checkpoint).[0-9]*.gz') as x
SQL
	# don't load any checkpoints or journals earlier than
	# the last labelled file we read
	my $min_interesting = ($already_got->{max}||-1) + 1;
	my $min_checkpoint = max
		((map {
			m{checkpoint.(\d+).gz} ? $1 : 0
		} @files),
		 $min_interesting-1);
	mutter "min interesting: $min_interesting";
	mutter "min checkpoint:  $min_checkpoint";
	$min_interesting = $min_checkpoint
		unless $min_interesting >= $min_checkpoint;

	if ( $min_checkpoint ) {
		@files = grep {
			if ( ( m{(checkpoint|journal).(\d+).gz}
			       and $2 < $min_interesting ) ) {
				mutter "ignoring $_ - not interesting";
				0;
			}
			elsif ( ( m{journal.(\d+).gz}
				  and $1 <= $min_checkpoint ) ) {
				mutter "ignoring $_ - using checkpoint";
				0;
			} else {
				1;
			}
		} @files;
	}
	say "Remaining files: @files";
	no_filter:

	my $marks_dirty;

	my %sth;
	while ( my $filename = shift @files ) {
		say "loading data from $filename";
		start_timer;
		my $open_filename = $filename;
		if ( $filename =~ m{\.gz$} ) {
			$open_filename = "zcat $filename|";
		}
		my %wanted =
			( "db.desc" => "change_desc",
			  "db.integed" => "integed",
			  "db.change" => "change",
			  "db.revcx" => "revcx",
			  "db.user" => "p4user",
			  "db.rev" => "rev",
			  "db.label" => "label",
			  "db.change_branches" => "change_branches",
			  "db.change_parents" => "change_parents",
			  "db.marks" => "marks",
			  "db.rev_marks" => "rev_marks",
			  "db.change_marks" => "change_marks",
			);
		my $get_sth = sub {
			my ($table, $size)=@_;
			$sth{$table."\0".$size} ||= do {
				if ( $load_opts{reload} ) {
					unless (scalar(grep m{^\Q$table\E\0},
						       keys %sth) > 1) {
						$dbh->do(<<SQL)
create temporary table "${table}_new" (like "${table}")
SQL
							or die $dbh->errstr;
					}
					$table .= "_new";
					mutter "loading into temp table $table";
				}
				my $sql = "INSERT INTO $table "
					."VALUES (".join(",",("?")x$size).")";
				whisper "Preparing: $sql";
				$dbh->prepare($sql);
			};
		};
		my $wanted_re = join "|", keys %wanted;
		my $regex_wanted = qr/(?:$wanted_re)/;
		open JOURNAL, "$open_filename" or die $!;
		#binmode JOURNAL, ":encoding(iso-8859-1)";
		my ($rows, $dirty, $dirty_rows);
		$dbh->begin_work;
		$dbh->{AutoCommit} = 0;
		$dbh->{PrintError} = 0;
		my %count;
		while ( <JOURNAL> ) {
			next unless m{^\@pv\@\s\d+\s@($regex_wanted)@};
			my $db = $wanted{$1};
			my @columns;
			while ( (pos($_)||0)+1 < length $_ ) {
				my $pre = pos $_;
				my $ok = m{\G(?:\@((?:[^@]+|\@\@)*)\@|(-?\w+)|(\\N))\s}g;
				if ( !$ok ) {
					pos($_) = $pre;
				}
				my ($string, $token, $null)
					= ($1, $2, $3) if $ok;
				if ( defined $string ) {
					$string =~ s{\@\@}{\@}g;
					utf8::upgrade($string);
					push @columns, $string;
				}
				elsif ( defined $token ) {
					push @columns, $token;
				}
				elsif ( $null ) {
					push @columns, undef;
				}
				else {
					die "end of file; $_" if eof JOURNAL;
					my $p = pos $_;
					pos($_)=0;
					my $line;
					my @extra;
					do {
						$line = readline JOURNAL;
						push @extra, $line;
					} until ($line =~ m{@\s*$});
					$_.=join("",@extra);
					pos($_) = $p;
					redo;
				}
			}
			@columns = (@columns[3..$#columns]);
			my $sth = $get_sth->($db,scalar(@columns)+1);
			eval {
				$sth->execute($filename, @columns);
				$rows++;
				$dirty_rows++;
				$dirty+=sum map {
					defined($_) ? length($_) : 0
				} @columns;
				if ( $VERBOSE > 1 ) {
					print "Saved: $columns[0]\n";
				}
			};
			if ( $@ ) {
				barf "DBI error ($@); Data: ".Dumper(\@columns);
			}
			$count{$db}++;
			if ( $db eq "marks" ) {
				$marks_dirty++;
			}
			if ( $dirty > (1<<18) or $dirty_rows >= 5000 ) {
				say "commit after $rows rows: ".
					join("; ", map{"$count{$_} x $_"}
					     keys %count);
				%count=();
				$dirty = 0;
				$dirty_rows = 0;
				$dbh->commit;
				$dbh->begin_work;
			}
		}
		$dbh->commit;
		$dbh->{AutoCommit} = 1;
		say "Loaded $rows rows from $filename in ".show_elapsed
			if $rows;
	}

	if ( $load_opts{reload} ) {
		my %tables = map { $_ => 1 } map { m{(.*)\0} }
				    keys %sth;
		my @tables;
		for my $table ( qw( user
				    change change_desc
				    rev revcx
				    integed
				    marks
				    rev_marks
				    change_branches
				    change_parents
				    change_marks
				 ) ) {
			if ( $tables{$table} ) {
				push @tables, $table;
			}
		}
		say "Loading tables in this order: @tables";
		# Oh, whither MERGE INTO :)
		$dbh->begin_work;
		for my $table ( @tables ) {
			my $sth = $dbh->primary_key_info
				('', '', $table, {pg_onerow => 1});
			if ( !$sth ) {
				moan "failed to get primary key info for "
					.$table;
				next;
			}
			my $keys = $sth->fetchall_arrayref->[0][3]
				or do {
					moan "$table has no primary key!";
					moan "did NOT load ${table}_new in";
					next;
				};
			(my $first_key = $keys) =~ s{,.*}{};
			my $from_where = <<SQL;
from
	"${table}_new" tn
 	left join "$table" ttotheo
		using ($keys)
where
	ttotheo.$first_key is null
SQL
			my $sql = "select count(*) ".$from_where;
			mutter "counting new rows:";
			my ($num) = values%{row_iter($dbh, $sql)->()};
			say "merging $num rows from ${table}_new into $table";
			$sql = <<SQL;
insert into
	"$table"
select
	tn.*
$from_where
SQL
			mutter "with: ", $sql;
			$dbh->do($sql);
			if ( $table eq "marks" ) {
				$marks_dirty++;
			}
		}
		$dbh->commit;
	}
	if ( $marks_dirty ) {
		my ($top) = values%{row_iter($dbh,<<SQL)->()};
select max(mark)+1 from marks
SQL
		say "resetting gfi_mark to $top";
		$dbh->do("alter sequence gfi_mark "
			 ."restart with $top");
	}
}

sub _to_p4_journal_format {
	my $db_name = shift;
	return
		((join " ", map {
			my $x = $_;
			if ( looks_like_number $x ) {
				$x
			}
			else {
				if ( defined $x ) {
					$x =~ s{\@}{\@\@}g;
					"\@$x\@"
				}
				else {
					'\N'
				}
			}
		} ("pv", 3, "db.$db_name", @_))."\n");
}

sub _journal_p4_row {
	my $statefile = shift;
	my $table = shift;
	my $mode = ( -e $statefile ? ">>" : ">" );
	open JOURNAL, $mode, $statefile;
	print JOURNAL _to_p4_journal_format $table, @_;
	close JOURNAL;
}

sub add_p4users {
	my $dbh = shift;
	my $data = shift;
	my $statefile = "p4raw-extra-users.asv";
	for my $datum ( @$data ) {
		my ($who, $count) = @$datum;
		say "$who made $count changes";
		my ($realname, $email);
		do {
			$realname = prompt_string
				"Who was using this '$who' moniker?", $realname;
			say "'$realname' huh.  Ok.";
			$email = prompt_string
				("And what was (or is) their e-mail address?",
				 $email);
			say "Right, so I'll attribute commits from that usercode "
				."to $realname <$email>";
		} until ( prompt_Yn("Sound good?") );
		_journal_p4_row $statefile, "user",
			($who, $email, "", time, time,
			 $realname, "", 0, "", 0);
	}
	return $statefile;
}

sub do_check {
	my $dbh = shift;

	require Text::CSV_XS;

	open SQL, "<$SHARE/constraints.sql" or die $!;
	my $constraints = join "", <SQL>;
	close SQL;
	my $do_this;
	my $one_row;

	while ( $constraints =~ m{\G(?: ( \s* --(?-s:.*)
					  (?: \n\s*--(?-s:.*) )* )
			            | \s* (.*?) (?:;|\Z) ) }sgx ) {
		my ($comment, $sql) = ($1, $2);
		if ( $comment ) {
			$comment =~ s{^\s*--\s*}{}mg;
			if ( $comment =~ s{^FOUND: ((?-s:.*))\n?}{}ms ) {
				$do_this = $1;
			}
			else {
				undef($do_this);
			}
			if ( $comment =~ s{^ONEROW(?-s:.*)\n?}{}ms ) {
				$one_row = 1;
			}
			else {
				undef($one_row);
			}
			say $comment;
		}
		elsif ( $sql ) {
			$sql =~ s{^\s*}{}s;
			if ( $sql =~ m{^select}i ) {
				mutter "query: $sql";
				my $sth = $dbh->prepare($sql);
				$sth->execute;
				my $csv;
				if ( $VERBOSE > 0 or $one_row ) {
					$csv = Text::CSV_XS->new
						({binary => 1,
						  eol => "\n"});
					my @N = @{ $sth->{NAME} };
					$csv->print(\*STDOUT, \@N);
				}
				my $rows = 0;
				my @data;
				while ( my @row = $sth->fetchrow_array ) {
					if ( $csv ) {
						$csv->print(\*STDOUT, \@row)
							or barf $csv->error;
					}
					if ( $do_this ) {
						push @data, \@row;
					}
					$rows++;
				}
				if ( !$one_row ) {
					say "($rows rows".
						($rows&&$VERBOSE==0
						 ?"; use -v to see them"
						 :"").")";
				}
				if ( $do_this and $rows ) {
					no strict 'refs';
					my $statefile =
						&{"$do_this"}($dbh, \@data);
					if ( $statefile ) {
						eval {
							do_load($dbh, $statefile);
						};
						moan("load of new data failed; $@")
							if $@;
					}
				}
			}
			else {
				mutter "running: $sql";
				eval { local($dbh->{PrintError});
				       $dbh->do($sql) };
				if ( $@ ) {
					my $x = $@;
					chomp($x);
					say "error from DB ($x), continuing"
						unless $x =~ m{already exists};
				}
			}
		}
	}
}

sub do_find_change {
	my $dbh = shift;
	my $rev = shift;
	$rev or abort "no revision passed to find-change";

	if ( $rev =~ m{^\d{1,6}$} ) {
		show_git_paths($dbh, $rev);
	}
	elsif ( $rev =~ m{^[a-f0-9]{40}$} ) {
		show_p4_change($dbh, $rev);
	}
	else {
		my ($rc, $revision) = capture_err
			(-out2 => "/dev/null",
			 qw(git rev-parse --verify), $rev);

		if ( $? ) {
			barf "'$rev' is not a valid revision";
		}
		chomp($revision);
		show_p4_change($dbh, $revision);
	}
}

sub show_p4_change {
	my $dbh = shift;
	my $git_rev = shift;

	my $query = $dbh->prepare(<<SQL);
select
	cm.change,
	cm.branchpath
from
	change_marks cm
	inner join marks m using (mark)
where
	m.commitid = ?
SQL
	$query->execute($git_rev);
	my $x = $query->fetchrow_hashref;
	$query->finish;

	if ( !$SCRIPT_MODE ) {
		if ( $x ) {
			say "commit ".substr($git_rev, 0, 12)
				.(" is Change $x->{change} on branch "
				  .$x->{branchpath});
		}
		else {
			barf "commit $git_rev not found in DB";
		}
	}
	else {
		if ( $x ) {
			print "$x->{change},$x->{branchpath}\n";
		}
		else {
			exit 1;
		}
	}
}

sub show_git_paths {
	my $dbh = shift;
	my $change = shift;

	my $query = $dbh->prepare(<<SQL);
select
	m.commitid,
	cm.branchpath
from
	change_marks cm
	inner join marks m using (mark)
where
	cm.change = ?
SQL
	$query->execute($change);
	my @d;
	while ( my $x = $query->fetchrow_hashref ) {
		push @d, $x;
	}
	$query->finish;

	if ( !$SCRIPT_MODE) {
		if ( @d > 1 ) {
			say "change $change affected multiple branches:";
			for ( @d ) {
				print "branch $_->{branchpath}, see "
					."commit $_->{commitid}\n";
			}
		}
		elsif ( @d ) {
			say "change $change was on branch "
				.("$d[0]{branchpath}, see commit "
				  .$d[0]{commitid}."\n");
		}
		else {
			barf "change $change not found in DB.  perhaps it was cancelled?";
		}
	}
	else {
		if ( @d ) {
			print "$_->{commitid},$_->{branchpath}\n"
				for @d;
		}
		else {
			exit 1;
		}
	}
}


sub do_filelog {
	my $dbh = shift;
	my %filelog_opts;
	{
		@ARGV = @_;
		getopt("i" => \$filelog_opts{follow_branches},
		       "t" => \$filelog_opts{show_time},
		       "l" => \$filelog_opts{show_desc},
		       "L" => \$filelog_opts{show_some_desc},
		       "m=i" => \$filelog_opts{maxRevs},
		      );
		@_ = @ARGV;
	}

	my ($follow_branches, $show_type, $show_desc, $show_some_desc,
	    $maxRevs);
	my @placeholders;
	my $pathspec = shift;
	my ($depotpath, $rev) = ($pathspec =~ m{^(.*?)(?:#(\d+))?$});

	show_filelogs($dbh, $depotpath, $rev, \%filelog_opts);
}

sub _p4_disp_rev {
	my $low = shift;
	my $high = shift;
	$low++;
	($low == $high ? "#$high" : "#$low,#$high");
}

# this function converts a perforce type bitmap to a text type.  I
# didn't try very hard to understand the layout or make this function
# very clever, I just cared about the types I saw in my own test
# repository.
use constant P4_TYPE_EXEC => 0b10_0000_0000;
use constant P4_TYPE_KORRUPT => 0b10_0000;  # korrupt on checkout
sub _p4_type {
	my $type = shift;
	my @supp;
	if ($type & 4096) {
       		$type ^= 4096;
		push @supp, "+w";
	}
	return join "",
		($type ==              0 ? "text"     :
		$type ==   0b1_0000_0011 ? "binary"   :
		$type ==   0b1_0000_0001 ? "ubinary"  :
		$type ==    P4_TYPE_EXEC ? "xtext"    :
		$type == P4_TYPE_KORRUPT ? "ktext"    :
		$type ==  0b10_0010_0000 ? "kxtext"   :
		$type ==  0b01_0000_0000 ? "binary+D" :
		$type ==0b1101_0000_0011 ? "apple"    :
		$type == 0b100_0000_0000 ? "symlink"  : "xxx-".sprintf("%b",$type)),
		@supp;
}

sub _p4_changelog {
	my $row = shift;
	my $o = shift || {};
	my @rv = ("$row->{change} ",
		  (defined $row->{change_type}
		   ? ($row->{change_type}, " ") : ()),
		  "on $row->{when} by $row->{who_user}",
		  "\@$row->{who_host}",
		  ($row->{file_type}
		   ? (" (",_p4_type($row->{file_type}), ")") : ()));

	if ( $o->{show_desc} || $o->{show_some_desc} ) {
		push @rv, "\n\n",
			(map { "\t$_\n" }
			 split /\n/,
			 ( $o->{show_some_desc}
			   ? substr $row->{description}, 0, 250
			   : $row->{description} ));
		push @rv, "\n";
	}
	else {
		my $short = $row->{short_desc};
		$short =~ s{\s}{ }g;
		push @rv, " '$short'\n";
	}
	@rv;
}

sub show_filelogs {
	my $dbh = shift;
	my $depotpath = shift;
	my $rev = shift;
	my $o = shift;

	# build the query.
	my @placeholders;

	my $time_fmt = 'YYYY/MM/DD';
	if ( $o->{show_time} ) {
		$time_fmt .= ' HH:MI:SS';
	}
	push @placeholders, $time_fmt, $depotpath;

	my $revision_clause = '';
	if ( $rev ) {
		$revision_clause = 'and revision <= ?';
		push @placeholders, $rev;
	}

	my $limit_clause = '';
	if ( $o->{maxRevs}) {
		$limit_clause = "limit ?";
		push @placeholders, $o->{maxRevs};
	}

	my $x = $o->{select_extra}||"";

	my $output = $o->{output_func};
	if ( !$output ) {
		$output = sub {
			my $row = shift;
			my $ii = shift;
			print "... #$row->{revision} change ",
				_p4_changelog($row, $o);
			while ( my $i = $ii->() ) {
				my $other;
				my ($low, $high);
				if ( $i->{subject} eq $row->{depotpath} ) {
					$other = $i->{object};
					($low, $high) = @{$i}{
						qw(object_minrev
						   object_maxrev)};
				}
				else {
					$other = $i->{subject};
					($low, $high) = @{$i}{
						qw(subject_minrev
						   subject_maxrev)};
				}
				my $disp_rev = _p4_disp_rev($low, $high);
				print "... ... $i->{int_title} $other",
					"$disp_rev\n";
			}
		};
	}
	my $oh = $o->{output_header} || sub {
		print "$depotpath\n";
	};
	my $long_desc = "";
	my $desc_join = "";
	if ( $o->{show_desc} or $o->{show_some_desc} ) {
		$long_desc = "\tchange_desc.description,";
		$desc_join = "\tleft join change_desc\n"
			."\t\tusing (change_desc_id)";
	}

	my $sql = <<SQL;
select
$long_desc
$x
	to_char(to_timestamp(change_time), ?) as when,
	*
from
	revcx_path
$desc_join
where
	depotpath = ? $revision_clause
order by
	revision desc
$limit_clause
SQL
	whisper "running: $sql";
	my $query = $dbh->prepare($sql);
	$query->execute(@placeholders);

	my $integed_fetch = $dbh->prepare(<<SQL);
select
	integed.*,
	int_type.title as int_title
from
	integed
	inner join int_type
		using (int_type)
where
	(subject = ? and subject_maxrev = ?)
	-- or (object = ? and object_maxrev = ?)
order by
	object, object_maxrev desc
SQL
	$oh->();
	while ( my $row = $query->fetchrow_hashref ) {
		my $executed;
		my $int_rows_iter = sub {
			$integed_fetch->execute
				($depotpath, $row->{revision})
					unless $executed++;
			$integed_fetch->fetchrow_hashref;
		};
		$output->($row, $int_rows_iter);
	}
}

sub do_integrated {
	my $dbh = shift;
	my %integed_opts;
	{
		@ARGV = @_;
		getopt("r" => \$integed_opts{reverse},
		      );
		@_ = @ARGV;
	}

	my $depotpath = shift;

	show_integes($dbh, $depotpath, \%integed_opts);
}

sub show_integes {
	my $dbh = shift;
	my $depotpath = shift;
	my $o = shift;

	my $which = "subject";
	if ( $o->{reverse} ) {
		$which = "object";
	}

	my $output = $o->{output} || sub {
		my $row = shift;
		my $subj_dr = _p4_disp_rev
			($row->{subject_minrev}, $row->{subject_maxrev});
		my $obj_dr = _p4_disp_rev
			($row->{object_minrev}, $row->{object_maxrev});

		print "$row->{subject}$subj_dr - ",
			("$row->{int_title} $row->{object}$obj_dr",
			 "\n");
	};

	my $sth = $dbh->prepare(<<SQL);
select
	integed.*,
	int_type.title as int_title
from
	integed
	inner join int_type
		using (int_type)
where
	$which = ?
order by
	object,
	object_minrev,
	subject_maxrev
SQL

	$sth->execute($depotpath);

	while ( my $row = $sth->fetchrow_hashref ) {
		$output->($row);
	}
}

sub do_describe {
	my $dbh = shift;

	my $write;
	my %desc_opts;
	{
		@ARGV = @_;
		getopt( "l" => \$desc_opts{long},
			"w" => \$write,
			"f" => \$desc_opts{derive_again},
		      );
		@_ = @ARGV;
	}
	abort "no change passed to describe" if !@_;

	my $change = shift;
	if ( $change !~ m{^\d+$} ) {
		abort "'$change' is not a valid change number";
	}

	if ( !$write ) {
		$desc_opts{add_change_branch} = sub {
			my $branch = shift;
			my $change = shift;
			print "action: add change_branch for $branch\@$change\n";
		};
		$desc_opts{add_parent} = sub {
			my $row = shift;
			my $bad;
			if ( defined $row->{none_unseen} and
			     ! $row->{none_unseen}) {
				$bad = 1;
			}
			print "action: add $row->{parent_branchpath}\@"
				.("$row->{parent_change} as a parent of"
				  ." $row->{branchpath}\@$change"
				  .($bad ? " (BAD MERGE)" : "")
				  ."\n");
		};
	}

	$dbh->begin_work;
	change_stats($dbh, $change, \%desc_opts);
	$dbh->commit;
}

sub change_branches_iter {
	my $dbh = shift;
	my $change = shift;
	my $what = shift;
	my $o = shift;
	my ($filter, $select, $group);
	if ( $what eq "eq" ) {
		$filter = "change = ?";
		$select = "change";
	}
	elsif ( $what eq "max" ) {
		$filter = "change <= ?";
		$select = "max(change) as change";
		$group = 1;
	}
	elsif ( $what eq "min" ) {
		$filter = "change <= ?";
		$select = "min(change) as change";
		$group = 1;
	}
	my $join = "";
	if ( $o->{commits} ) {
		$join = "\tjoin change_marks using (branchpath,change)\n"
			."\tjoin marks using (mark)\n";
		$select .= ",\n\tcommitid";
	}
	my $sql = (<<SQL.($group?<<SQL:""));
select
	branchpath,
	$select
from
	change_branches
$join
where
	$filter
SQL
group by
	branchpath
SQL
	row_iter($dbh, $change, $sql);
}

sub derive_branch_src {
	my $path = shift;
	my $PcO = shift;
	my $callback = shift;
	my $branches = $PcO->{branch};
	if ( keys %$branches > 1 ) {
		print "multiple branch sources for $path, erp!";
		print "Too many parents: @{[ map{ $_||$path } keys %$branches ]}\n";
	}
	while ( my ($source_path, $info) = each %$branches ) {
		$callback->({ branchpath => $path,
			      parent_branchpath => $source_path,
			      parent_change => $info->{int_change},
			      manual => 0,
			    });
	}
}

sub row_iter {
	my $dbh = shift;
	my $sql = pop;
	my @args = @_;
	my $sth;
	my @putback;
	my $deplete;
	sub {
		if ( @_ ) {
			push @putback, @_;
			return ();
		}
		elsif ( @putback ) {
			return pop @putback;
		}
		if ( !$sth and !$sql ) {
			return undef;
		}
		if ( !$sth ) {
			if ( ref $sql ) {
				$sth = $sql;
			}
			else {
				$sth = $dbh->prepare($sql)
					or die $dbh->errstr;
			}
			$sth->execute(@args) or die $sth->errstr;
		}
		my $rv = $sth->fetchrow_hashref;
		if ( !$rv ) {
			$sth->finish;
			undef($sth);
			undef($sql);
		};
		$rv;
	}
}

sub derive_extra_parents {
	my $dbh = shift;
	my $path = shift;
	my $change = shift;
	my $PcO = shift;
	my $POc = {%{+shift}};
	my $prev = shift;
	my $callback = shift;

	my $root_changes = delete $POc->{""};
	my $confused_changes = delete $POc->{$path};
	my $has_changes = !!($root_changes || $confused_changes);
	my @extra;
	push @extra, evil => 1 if $has_changes;

	# warn for octopus and evil merges
	if ( keys %$POc > 1 ) {
		print( ($has_changes ? "Shoggoth" : "Octopus")
		       ." merge of: @{[map { $_||$path} keys %$POc]}\n" );
		push @extra, octopus => 1;
	}
	elsif ( !keys %$POc ) {
		print "Intra-branch integrate.  Sick.\n";
	}
	elsif ( $has_changes ) {
		print "This is an EVIL merge\n";
	}

	my $manual;
	my @parents =
		{ branchpath => $path,
		  parent_branchpath => $path,
		  parent_change => $prev->{$path},
		  manual => 0 };

	my @ignored;

	# add all parents
	while ( my ($source_path, $chg_info) = each %$POc ) {

		my @extra_per_src;
		my ($all_headrev, $none_unseen, $o_change );
		$o_change = max map { $_->{int_subj_max_change}||-1 }
			map { @$_ } map { values %$_ }
				values %$chg_info;
		if ( !grep { !$_->{int_subj_headrev} }
		     map { @$_ } map { values %$_ }
		     values %$chg_info ) {
			$all_headrev = 1;
			$o_change = $prev->{$source_path};
		}

		# prepare a list of relative paths that are integrated
		# by this change.
		my %integrated;
		my $integed_c;
		my %revcx_by_relpath;
		while ( my ($type, $c_d) = each %{$POc->{$source_path}} ) {
			for my $revcx ( @{ $c_d->{revcxs} } ) {
				my $relpath = $revcx->{int_obj};
				$relpath =~ s{^\Q$source_path\E/}{} &&
					($integrated{$relpath}++);
				$integed_c++;
				$revcx_by_relpath{$relpath}=$revcx;
			}
		}
		# now here's the fancy-pants stuff.  Find the merge base...
		my (@mb) = find_merge_base
			($dbh,
			 [ $path, $prev->{$path} ],
			 [ $source_path, $o_change ]);
		print "merge base of $path\@$prev->{$path} and "
			.("$source_path\@$o_change is "
			  ."@{[ map { join '@', @$_ } @mb ]}\n");

		# ... then try a 3-way merge with each of the merge bases ...
		my $left = index_for_version($dbh, $path, $change);
		my $right = index_for_version($dbh, $source_path, $o_change);
		$none_unseen = 1;
		my $count = 0;
		my $moan_count = 0;
		my %unseen;
		my (%curious, %omitted);
		my %obvious;

		for my $mb ( @mb ) {

			# ok, so, it's actually *here* that we need to
			# pull down the integed rows.  This is
			# somewhat approximate; the assumption is made
			# that any changes that appear on a branch are
			# always on the ancestry tree back to the
			# merge base.  If you delete branches,
			# re-branch them from a point prior to that,
			# and then merge them this precondition may
			# break.  I think.
			my %old_integed;
			my $row_iter = row_iter
				($dbh, $path, $change, $source_path,
				 $o_change, $mb->[1], <<SQL);
select
	*
from
	integed
	join int_type using (int_type)
where
	(subject like (?||'/%') and change < ?)
and	(object like (?||'/%') and change < ?)
and	change > ?
SQL

			my $base = index_for_version($dbh, @$mb);
			my @changed = grep {
				 (!index_eq($right->{$_}, $base->{$_}) and
				  ((($right->{$_}&&$right->{$_}[4])||$change) > $mb->[1]) and
				  !( (index_eq($right->{$_}, $left->{$_}))
				    && do {
					    $obvious{$_}++;
					    $curious{$_}=0;
					    $omitted{$_}=0;
				    }))
				} keys %{{ %$right, %$base }};
			print "there were ".@changed." path(s) changed "
				.("between $mb->[0]\@$mb->[1] and "
				  ."$source_path\@$o_change\n");

			my $bad = 0;
			for my $relpath ( @changed ) {
				if ( !exists $integrated{$relpath} and
				     !$obvious{$relpath}
				   ) {
					$bad++;
					print("path $relpath ",
					      index_diff
					      ($base->{$relpath},
					       $right->{$relpath}),
					      " in $source_path".
					      ($right->{$relpath}?"\@$right->{$relpath}[4]":"")
					      ." but ",
					      index_diff
					      ($base->{$relpath},
					       $left->{$relpath}),
					      " in ", $path,
					      ($left->{$relpath}?" since change $left->{$relpath}[4]":""))
						unless ++$moan_count > 10;
					my $hmm;
					if ( my $x = $root_changes ) {
						if ( my $i = $x->{integrate} ) {
							for my $rcx ( @{$i->{revcxs}} ) {
								if ( $rcx->{depotpath} eq "$path/$relpath" ) {
									print " but unspec. integration found, so OK" unless $moan_count > 10;
									$hmm = 1;
								}
							}
						}
					}
					print "\n" unless $moan_count > 10;
					unless ($hmm) {
						# ok, so if we get here then call that row_iter
						if ( !keys %old_integed ) {
							print "Just checking for integs between changes "
								.(($mb->[1]+1)." and ".(max($change, $o_change)-1)
								  ." between $source_path and $path\n");
							while ( my $row = $row_iter->() ) {
								(my $relpath2 = $row->{subject}) =~ s{$path/}{};
								$old_integed{$relpath2} = $row;
							}
							$old_integed{\0}++;
						}
						if ( my $oi = $old_integed{$relpath} ) {
							print "BUT HOLD IT!  In change $oi->{change}, there was an $source_path $oi->{title} $path ($oi->{description}).  That'll do us.\n"
								unless $moan_count > 10;
						}
						else {
							$none_unseen = 0;
							$unseen{$relpath}++;
							if ( index_eq($base->{$relpath},
								      $left->{$relpath})) {
								$omitted{$relpath}++
									unless exists $omitted{$relpath};
							}
							else {
								$curious{$relpath}++
									unless exists $curious{$relpath};
							}
							if ( $VERBOSE > 1 ) {
								whisper "index info:",
									Dump({ left => $left->{$relpath},
									       right => $right->{$relpath},
									       base => $base->{$relpath} });
							}
						}
					}
				}
				else {
					$count++;
				}
			}
			if ( $moan_count > 10 ) {
				print "(total of $bad files not listed)\n"
			}
		}
		if ( $none_unseen ) {
			print "Confirmed $count differences all integrated - it's a merge!\n";
		}
		else {
			my $seen = keys %integrated;
			my $unseen = keys %unseen;
			my $total = $seen + $unseen;
			my $bo = keys %obvious;
			my $s_b_o = keys %{{ %obvious, %integrated }};
			delete @omitted{grep {!$omitted{$_}} keys %omitted};
			delete @curious{grep {!$curious{$_}} keys %curious};
			my $dis = keys %{{ %omitted, %curious }};
			my @bad = sort keys %{{ %omitted, %curious }};
			if ( @bad > 10 ) {
				$#bad = 9;
				push @bad, "...";
			}
			my $pc = sprintf "%d", (($s_b_o)/($s_b_o+$unseen))*100;
			my $adj = sub {
				\($_[0] > 95 ? "an overwhelming" :
				 $_[0] > 80 ? "a massive" :
				 $_[0] > 50 ? "about" :
				 $_[0] > 20 ? "only" :
				 $_[0] > 5  ? "a meagre" : "a pathetic");
			};
			my $o_pc = sprintf "%d", $seen/$total * 100;
			whisper "seen: $seen, unseen: $unseen, bo: $bo, pc:$pc opc:$o_pc, integed: $integed_c";
			print map { my $x = $_; $x =~ s{\n}{ }g;
				    wrap("","",$x)."\n\n" } split /\n\n/, <<THIS unless ($o_pc < 34 or $o_pc > 90);

Was this change was a merge in the git sense?

Integration records mention ${$adj->($o_pc)} $o_pc% of $total
path(s) that would support the hypothesis.

If it were, then that means ${$adj->($pc)} ${pc}% of possible
merges, were either mentioned in integration records or obvious.
There were $bo obvious merges and $seen paths mentioned in the
integration records.  $dis changes remain ambiguous (@bad).

Recording this as a merge is not necessarily the right thing to do; it
might be better to just record this as a separate change.
Alternatively you might be seeing a complicated merge unfold over
several commits, which is usually entirely disinteresting and should
be grafted away.

If it looks like the intent of this change is to merge ALL changes
from $source_path\@$o_change into $path,
then say "Yes".  Otherwise, say "No".  No information will be lost
either way; but getting this wrong will affect later merge-base
calculations, potentially making it harder to figure out what later
merges are.
THIS
			my $func = ($o_pc > 75 ? \&prompt_Yn : \&prompt_yN);
			# dirty hack - less than 1 in 25 => no
			if ( $o_pc > 90 or
			     ( $o_pc > 66 and @bad < 10 ) ) {
				$func = sub { 1 };
			}
			else {
				$func = sub { 0 };
			}
			unless ( $func->("Mark as a parent?") ) {
				push @ignored,
					$source_path => \%revcx_by_relpath;
				next;
			}
			#FIXME - these often aren't 'manual'
			$manual = 1;
			push @extra_per_src,
				(manual => 1,
				 (keys %unseen
				  ? (json_info => objToJson
				     ({omitted=>[grep { $omitted{$_} }
						 keys %omitted],
				       curious=>[grep { $curious{$_} }
						 keys %curious ]}))
				  : ()));
		}

		push @parents,
			{ branchpath => $path,
			  parent_branchpath => $source_path,
			  parent_change => $o_change,
			  all_headrev => $all_headrev,
			  none_unseen => $none_unseen,
			  manual => 0,
			  @extra, @extra_per_src };
	}
	for my $p ( @parents ) {
		if ( @ignored and !$p->{json_info} ) {
			$p->{json_info}=objToJson{integrated=>{@ignored}};
		}
		$callback->( ($manual and !$p->{manual})
			     ? {%$p} : $p );
	}
	if ( $manual ) {
		for my $p ( @parents ) {
			if ( ! $p->{manual} ) {
				$p->{manual} = 1;
				$callback->($p);
			}
		}
	}
}

sub do_lose_branches {
	my $dbh = shift;

	my %export_opts = parse_export_opts($dbh, "extant_branches", @_);

	say "forgetting branches for $export_opts{chunk_size} changes";
	$dbh->begin_work;
	for my $sql ( <<SQL, <<SQL ) {
delete from
	change_parents
where
	change between ? and ?
SQL
delete from
	change_branches
where
	change between ? and ?
SQL
		$dbh->do($sql, undef, $export_opts{min}, $export_opts{max});
	}
	$dbh->commit;
}

sub do_show_branches {
	my $dbh = shift;
	my $change = shift || max_change($dbh);
	if ( $change !~ m{^\d+$} ) {
		abort "bad change # '$change'";
	}
	my $branches = row_iter($dbh, $change, <<SQL);
select distinct on (cb.branchpath)
	cb.branchpath,
	cb.change,
	cm.commitid
from
	change_branches cb
	left join
		(select
			change,
			branchpath,
			commitid
		from
			change_marks
			join marks using (mark)) cm
	using (change, branchpath)
where
	change <= ?
order by
	cb.branchpath,
	change desc
SQL
	my %branches;
	while ( my $x = $branches->() ) {
		$branches{$x->{branchpath}} = [$x->{change},$x->{commitid}];
	}
	my $length = max map { length $_ } keys %branches;
	my $num_length = max map { length $_ } map { $_->[0] } values %branches;
	for my $branch ( sort keys %branches ) {
		print $branch, (" " x ($length - length($branch)
				       + $num_length
				       - length($branches{$branch}[0]) + 1)),
			($branches{$branch}[0], " ",
			 ($branches{$branch}[1]
			  ? substr($branches{$branch}[1], 0, 12)
			  : "-"),
			 "\n");
	}
}

use POSIX qw(strftime);

sub change_stats {
	my $dbh = shift;
	my $change = shift;
	my $o = shift;
	my $csv;

	# ok, so there are a few internal callbacks in this function.
	# the first gets the description of the change - roughly
	# change_desc
	my $show_header = $o->{show_header} || sub {
		my $d = shift;
		print "Change $d->{change} by $d->{who_user}\@",
			("$d->{who_host} on ",
			 strftime("%Y/%m/%d %H:%M:%S",
				   localtime($d->{change_time})));
		if ( $o->{compact} ) {
			print " '".substr($d->{description},0,40)."'\n";
		}
		else {
			print "\n\n";
			print map { "\t$_\n" } split "\n", $d->{description};
			print "\n";
		}
	};

	# this one gets called with the list of branches
	my %prev_paths;
	my %curr_paths;
	my $prepare_paths = sub {
		my $row = shift;
		if ( $row->{change} == $change ) {
			$curr_paths{$row->{branchpath}}++;
		}
		else {
			$prev_paths{$row->{branchpath}} = $row->{change};
		}
		$o->{prepare_path}->($row) if $o->{prepare_path};
	};

	# this one receives any pre-existing change_parents rows
	my %parents;
	my $change_parents = sub {
		my $row = shift;
		push @{ $parents{$row->{branchpath}} ||= [] }, $row;
		$o->{change_parents}->($row) if $o->{change_parents};
	};

	# this one gets change_detail 'rows'
	my $show_change_detail = $o->{show_change_detail} = sub {
		my $path = shift;
		my $details = shift;
		print "On path $path,\n";
		while (my ($change_title, $by_int_path)
		       = each %$details) {
			for my $int_path (sort keys %$by_int_path) {
				my $c_d = $by_int_path->{$int_path};
				print "\t", $change_title, " ";
				if ( $int_path ) {
					print "from $int_path ("
						.($c_d->{int_headrev}
						  ?"head":
						  $c_d->{int_change})."), ";
				}
				print scalar(@{$c_d->{revcxs}})," file(s)";
				print "\n";
				if ( $o->{long} ) {
					for my $c ( @{$c_d->{revcxs}} ) {
						show_chg($path, $c);
					}
				}
			}
		}
		print "\n";
	};

	goto no_header if !ref $show_header;
	my $sth = $dbh->prepare(<<SQL);
select
	*
from
	change_desc
	inner join change
		using (change_desc_id)
where
	change.change = ?
SQL
	$sth->execute($change);
	my $row = $sth->fetchrow_hashref;
	if ( !$row ) {
		say "no such change $change";
		return;
	}
	if ( !$row->{closed} ) {
		moan "change $change was not closed";
	}
	$show_header->($row);
	$sth->finish;

no_header:
	my $iter = change_branches_iter($dbh, $change-1, "max");
	while ( my $row = $iter->() ) {
		$prepare_paths->($row);
	}
	$iter = change_branches_iter($dbh, $change, "eq");
	while ( my $row = $iter->() ) {
		$prepare_paths->($row);
	}
	undef($iter);

	my $know_parents;
	$sth = $dbh->prepare(<<SQL);
select
	*
from
	change_parents
where
	change = ?
order by
	manual desc
SQL
	$sth->execute($change);
	while ( my $row = $sth->fetchrow_hashref ) {
		$know_parents++;
		$change_parents->($row);
	}
	$sth->finish;

	$sth = $dbh->prepare(<<SQL);
select
	*,
	change_type.title as change_title
from
	revcx_integed
	inner join change_type
		using (change_type)
where
	change = ?
order by
	depotpath
SQL
	$sth->execute($change);
	my (@revcxs);

	my $path_re;
	my %paths = (%prev_paths, %curr_paths);
	my $add_path = sub {
		if ( @_ ) {
			if ( grep { (!$_[1] or defined $paths{$_[0]})
					    and m{^\Q$_[0]\E/} } keys %paths ) {
				return undef;
			}
			$paths{(shift)} ||= undef;
		}
		if ( keys %paths ) {
			my $re = join("|",sort { length($b)<=>length($a) }
				      map{"\Q$_\E"} keys %paths);
			$path_re = qr{$re};
		}
		else {
			$path_re = qr{(?!.)};
		}
	};
	$add_path->();

	# now, set about grouping the revcx_integed stuff by branch,
	# change type and integrated branch
	while ( my $row = $sth->fetchrow_hashref ) {
		# try to figure out the branch root by looking for top
		# level changes, or integrates from other paths.  Hope
		# no integrations are happening between files with
		# different names!
		my $path = $row->{depotpath};
		unless ( $path =~ m{^($path_re)/} ) {
			# new path, add to paths
			$path =~ s{/[^/]*$}{};
			if ( $row->{int_obj} and
			     $row->{int_obj} =~ m{^($path_re)/} ) {
				$path = substr $row->{depotpath}, 0,
					length($row->{depotpath}) -
					(length($row->{int_obj}) -
					 length $1);
			}
			elsif ( $row->{int_obj} ) {
				$path = diff_right($row->{int_obj},
						   $row->{depotpath});
				moan "using diff_right($row->{int_obj}, $row->{depotpath}) for change branch path (=$path)";
			}
			else {
				mutter "adding new branchpath $path because I saw $row->{depotpath}";
			};
			$add_path->($path, 1);
		}
		push @revcxs, $row;
		$o->{revcxs}->($row, $path) if $o->{revcxs};
	};

	# remove the paths that shadow each other.
	my @gonners = grep { m{^($path_re)/} } keys %paths;
	if ( @gonners ) {
		for my $gonner ( @gonners ) {
			if ( $prev_paths{$gonner} ) {
				# this new change would appear to shadow others.
				# so, nuke it.
				if ( $gonner =~ m{^($path_re)/} ) {
					my $culprit = $1;
					moan "$culprit shadows branches: "
						.join(" ", grep m{^\Q$culprit\E/},
						      @gonners);
					delete $paths{$1};
					$add_path->();
				}
			}
			else {
				moan "ignoring changes on path $gonner\@$change";
				delete $paths{$gonner};
			}
		}
		$add_path->();
	}

	# ok, now group them by path and integration branch, and change type
	my (%by_path_chg_obj, %by_path_obj_chg);
	my @change_details;
	for my $row ( @revcxs ) {
		{ no warnings;
		#whisper "row: $row->{depotpath} $row->{change_title} $row->{int_obj}";
	  }
		my ($path) = ($row->{depotpath} =~ m{^($path_re)/})
			or do {
				moan "$row->{depotpath} will NOT be imported";
				next;
			};

		my $op = "";
		if ( $row->{int_obj} &&
		     $row->{int_obj} =~ m{^($path_re)/} ) {
			$op = $1;
		}
		elsif ( $row->{int_obj} ) {
			$op = diff_right($row->{depotpath},
					 $row->{int_obj});
			moan "using diff_right($row->{depotpath}, $row->{int_obj}) for integration branchpath (=$op)";
			while ( !$add_path->($op) ) {
				($op) = $row->{int_obj} =~ m{^(\Q$op\E/[^/]+)};
				moan "no, that'll shadow something, use $op instead";
			};
		}
		my $c_d = $by_path_chg_obj{$path}{$row->{change_title}}{$op}
			||= do {
			my $change_detail =
				{ branchpath => $path,
				  change_title => $row->{change_title},
				  int_branch => $op,
				  revcxs => []
				};
			push @change_details, $change_detail;
			$change_detail;
		};
		$by_path_obj_chg{$path}{$op}{$row->{change_title}} = $c_d;
		push @{$c_d->{revcxs}}, $row;
	}

	# within those groups, see if the changes are all headrev or
	# their max_change
	for my $c_d ( @change_details ) {
		$c_d->{int_change} =
			max map { $_->{int_subj_max_change}||-1 }
				@{$c_d->{revcxs}};
		$c_d->{int_headrev} =
			!(grep {
				!$_->{int_subj_headrev}
			} @{$c_d->{revcxs}});
	}

	my $show_parent = sub {
		my $row = shift;
		print "Parent: ",
			(($row->{ref} ? "$row->{ref}"
			  : ("$row->{parent_branchpath}\@"
			     ."$row->{parent_change}")),
			 ((!$row->{ref}&&$row->{manual})
			  ? " (manual)" : ""),
			 ((defined($row->{none_unseen})&&!$row->{none_unseen})
			  ? " (tenuous)" : ""),
			 ($row->{evil} ? " (EVIL)" : ""),
			 "\n");
		if ( $row->{json_info} ) {
			print map { $_, "\n" }
				show_juice($row, jsonToObj($row->{json_info}));
		}
	};

	my $add_parent_sth;
	my $add_parent = sub {
		my $row = shift;
		$show_parent->($row);
		if ( $o->{add_parent} ) {
			$o->{add_parent}->($row);
			return;
		}

		my @cols = keys %$row;
		$add_parent_sth = $dbh->prepare(<<SQL);
insert into change_parents
	(${\(join ", ", @cols)})
values
	(${\(join ", ", ("?") x @cols)})
SQL
		my @row;
		for my $col ( @cols ) {
			push @row, $row->{$col};
		}
		mutter "saving new parent:\n"
			.join("\n", map { "\t$_: ".(defined($row->{$_})?$row->{$_}:"NULL") }
			      sort keys %$row)
			if $VERBOSE >= 1;
		$add_parent_sth->execute(@row);
	};
	my $add_change_branch_sth;
	my $add_change_branch = $o->{add_change_branch} ||= sub {
		$add_change_branch_sth ||= $dbh->prepare(<<SQL);
insert into change_branches
	(branchpath, change)
values (?, ?)
SQL
		mutter "saving new branch path: @_";
		$add_change_branch_sth->execute(@_);
	};

	my @ncp;
	my $new_change_parents = sub {
		my $row = shift;
		$row->{change} = $change;
		push @ncp, $row;
		$change_parents->($row);
	};
	# derive extra parents if necessary
        for my $path ( sort keys %by_path_chg_obj ) {
		$add_change_branch->($path, $change)
			unless $curr_paths{$path};
		my $PcO = $by_path_chg_obj{$path};
		$show_change_detail->($path, $PcO);
		my $POc = $by_path_obj_chg{$path};
		my $parents = $parents{$path}||[];
		if ( grep { $_->{manual} } @$parents ) {
			$parents = [ grep { $_->{manual} } @$parents ];
		}
		if ( $know_parents ) {
			for ( @$parents ) {
				$show_parent->($_);
			}
		}
		$DB::single = 1;
		my $has_other_paths = grep { length && $_ ne $path }
			keys %$POc;

		if ( !exists $prev_paths{$path} ) {
			if ( exists $PcO->{integrate} or
			     exists $PcO->{delete} or
			     exists $PcO->{edit}
			   ) {
				moan "new path $path\@$change has non-new changes, odd";
			}
			if ( !$know_parents and $PcO->{branch} and
			     $has_other_paths
			   ) {
				# derive the branch's parent
				derive_branch_src $path, $PcO
					=> $new_change_parents;
			}
		}
		elsif ( grep { length && $_ ne $path } keys %$POc ) {
			# some inter-branch action.
			if ( !$know_parents or $o->{derive_again} ) {
				derive_extra_parents $dbh, $path, $change,
					$PcO, $POc,
					\%prev_paths,
					=> $new_change_parents;
			}
		}
		else {
			if ( !$know_parents ) {
				$new_change_parents->
					({ branchpath => $path,
					   parent_branchpath => $path,
					   manual => 0,
					   parent_change => $prev_paths{$path},
					 });
			}
		}
		if ( !$know_parents ) {
			for my $row (@ncp) {
				$add_parent->($row);
			}
			@ncp=();
		}
	}
}

sub show_chg {
	my $path = shift;
	my $chg = shift;

	print "\t\t";
	my $filename = substr $chg->{depotpath}, length $path;
	if ( $chg->{int_obj_title} ) {
		my $odr = _p4_disp_rev
			($chg->{int_obj_min}, $chg->{int_obj_max});
		my $sdr = _p4_disp_rev
			($chg->{int_subj_min}, $chg->{int_subj_max});
		if ( $sdr =~ m{,} ) {
			$sdr .= " ($chg->{int_subj_min_change},"
				."$chg->{int_subj_max_change})";
		}
		else {
			$sdr .= " ($chg->{int_subj_max_change})";
		}
		if ( $chg->{int_subj_headrev} ) {
			$sdr .= "(HEAD)";
		}

		print "...$filename: $sdr $chg->{int_obj_title} "
			.($odr ne "#$chg->{revision}" ? "$odr" : "us"),
				"\n";
	}
	else {
		print "...$filename\n";
	}
}

sub make_cc {  # only CC's eez tasting like theez
	my $self =
		{ path => shift,
		  change_title => shift,
		  changes => shift,
		  obj_path => shift,
		  obj_change => shift,
		  obj_headrev => shift };

	
}

sub diff_right {
	my $left = shift;
	my $right = shift;
	my $done = 0;
	while (!$done) {
		my ($last_component) = $left =~ m{(/[^/]+)$};

		if (!defined($last_component) or
			$right !~ s{\Q$last_component\E$}{}) {

			$done = 1;
		}
		else {
			$left =~ s{\Q$last_component\E$}{};
		}
	}
	return $right;
}

sub do_changes {
	my $dbh = shift;
	my %changes_opts;
	{
		@ARGV = @_;
		getopt("l" => \$changes_opts{show_desc},
		       "L" => \$changes_opts{show_some_desc},
		       "m=i" => \$changes_opts{maxRevs},
		      );
		@_ = @ARGV;
	}

	my $pathspec = shift;
	my ($depotpath, $minRev, $maxRev)
		= ($pathspec =~ m{^(.*?)(?:#(\d+)(?:,#?(\d+))?)?$})
			if $pathspec;
	$maxRev = $minRev if !$maxRev;

	show_changes($dbh, $depotpath, $minRev, $maxRev, \%changes_opts);
}

sub show_changes {
	my $dbh = shift;
	my $depotpath = shift;
	my $minRev = shift;
	my $maxRev = shift;
	my $o = shift;

	my $output = $o->{output} ||= sub {
		my $row = shift;
		print "Change ", _p4_changelog($row, $o);
	};

	# build the query.  some code duplicated from show_filelogs,
	# CBA fixing for now...
	my @placeholders;

	my $time_fmt = 'YYYY/MM/DD';
	if ( $o->{show_time} ) {
		$time_fmt .= ' HH:MI:SS';
	}
	push @placeholders, $time_fmt;

	my @filters;

	my $long_desc = "";
	my $desc_join = "";
	if ( $o->{show_desc} or $o->{show_some_desc} ) {
		$long_desc = "\tchange_desc.description,";
		$desc_join = "\tleft join change_desc\n"
			."\t\tusing (change_desc_id)";
	}

	my $limit_clause = '';
	if ( $o->{maxRevs}) {
		$limit_clause = "limit ?";
		push @placeholders, $o->{maxRevs};
	}

	my $revcx_join = "";
	if ( $depotpath ) {
		$revcx_join = "\tinner join revcx\n"
			.("\t\ton (revcx.change = change.change and\n"
			  ."\t\t\trevcx.depotpath = ?)");
		push @placeholders, $depotpath;
	}

	if ( $maxRev ) {
		if ( $minRev ) {
			push @filters, 'revision between ? and ?';
			push @placeholders, $minRev, $maxRev;
		}
		else {
			push @filters, 'revision <= ?';
			push @placeholders, $maxRev;
		}
	}

	my $where_clause = "";
	if ( @filters ) {
		$where_clause = "where\n\t".join("\nand\t", @filters);
	}

	my $sql = <<SQL;
select
$long_desc
	to_char(to_timestamp(change_time), ?) as when,
	change.*
from
	change
$revcx_join
$desc_join
$where_clause
order by
	change.change desc
$limit_clause
SQL
	if ( $VERBOSE>1) {
		say "querying changes with: $sql";
		say "placeholders: (".join(", ", @placeholders).")";
	}
	my $sth = $dbh->prepare($sql);
	$sth->execute(@placeholders);
	while ( my $row = $sth->fetchrow_hashref ) {
		$output->($row);
	}
}

sub max_change {
	my $dbh = shift;
	my $o = shift;
	my $sql = <<SQL;
select
	max(change)
from
	change
SQL
	if ( $o and $o->{extant_branches} ) {
		$sql .= <<SQL;
	join change_branches
		using (change)
SQL
	}
	my ($change) = map { @$_ } @{ $dbh->selectall_arrayref($sql) };

	return $change;
}

sub get_rcs {
	my $rcs_file = shift;
	my $rcs_revision = shift;
	return undef if !$rcs_file;
	$rcs_file =~ s{^//}{};
	my $cmd;
	if ( -f "$rcs_file,d/$rcs_revision" ) {
		$cmd = "cat '$rcs_file,d/$rcs_revision'";
	}
	elsif ( -f "$rcs_file,d/$rcs_revision.gz" ) {
		$cmd = "zcat '$rcs_file,d/$rcs_revision'";
	}
	else {
	#    In fact I'd be highly tempted to parse the RCS file
	#    directly, as it might be significantly faster to hold
	#    the latest version of each RCS file in memory, as we work
	#    backwards through the revisions and construct new
	#    versions of it for feeding to fast-import.  Consider an
	#    RCS file with many revisions; getting all revisions out
	#    with `co -p` will be O(N^2) but directly will be O(N)
		$cmd = "co -q -p$rcs_revision -kb '$rcs_file'";
	}
	open CMD, "-|", "$cmd" or die $!;
	binmode CMD;
	local($/) = \((stat CMD)[11]||4096);
	my @data = <CMD>;
	close CMD;
	join "", @data;
}

sub do_print {
	my $dbh = shift;
	my %print_opts;
	{
		@ARGV = @_;
		getopt("Q" => \$print_opts{quiet},
		       "c=i" => \$print_opts{change},
		       "a" => \$print_opts{all},
		      );
		@_ = @ARGV;
	}

	my $pathspec = shift;
	my ($depotpath, $rev)
		= ($pathspec =~ m{^(.*?)(?:#(\d+))?$})
			if $pathspec;

	show_file($dbh, $depotpath, $rev, \%print_opts);
}

sub show_file {
	my $dbh = shift;
	my $depotpath = shift;
	my $rev = shift;
	my $o = shift;
	my $change = $o->{change};

	if ( !$rev ) {
		$change ||= max_change($dbh);
	}

	my @where;
	my @pl;

	push @where, "depotpath = ?";
	push @pl, $depotpath;

	if ( !$rev ) {
		push @where, "change <= ?";
		push @pl, $change;
	}
	else {
		push @where, "revision = ?";
		push @pl, $rev;
	}

	my $where = join " and ", @where;
	my $limit = ($o->{all} ? "" : "limit 1");
	my $sth = $dbh->prepare(<<SQL);
select
	revision,
	rev_change_type,
	change,
	ct.title as change_title,
	file_type,
	rcs_file,
	rcs_revision,
	m.blobid
from
	rev
	inner join change_type ct
		on (ct.change_type = rev.rev_change_type)
	left join rev_marks rm
		using(depotpath,revision)
	left join marks m
		using (mark)
where
	$where
order by
	revision desc
$limit
SQL
	$sth->execute(@pl);
	my $output = $o->{output} || sub {
		my $row = shift;
		unless ( $o->{quiet} ) {
			print "$depotpath#$row->{revision} - "
				.("$row->{change_title} change "
				  .$row->{change}." ("._p4_type($row->{file_type})
				  .")".($row->{blobid}
					?" blob ".substr($row->{blobid},0,7)
					:"")."\n");
		}
		if ( $row->{blobid} ) {
			exec("git", "cat-file", "blob", $row->{blobid});
		}
		my $file_data = get_rcs($row->{rcs_file},
					$row->{rcs_revision});
		binmode STDOUT, ":raw";
		print $file_data;
	};
	while ( my $row = $sth->fetchrow_hashref ) {
		$output->($row);
	}
	$sth->finish;
}

sub do_ls_tree {
	my $dbh = shift;
	my %ls_tree_opts;
	{
		@ARGV = @_;
		getopt("l" => \$ls_tree_opts{length},
		       "b" => \$ls_tree_opts{blob},
		       "r" => \$ls_tree_opts{recurse},
		       "name-only" => \$ls_tree_opts{name_only},
		       "abbrev=i" => \$ls_tree_opts{abbrev},
		      );
		@_ = @ARGV;
	}

	my $pathspec = shift;
	my ($depotpath, $change)
		= ($pathspec =~ m{^(.*?)(?:@(\d+))?$})
			if $pathspec;
	if ( @_ or !$depotpath ) {
		abort "expected depot path/change (only)";
	}
	$change ||= max_change($dbh);

	show_files($dbh, $depotpath, $change, \%ls_tree_opts);
}

sub sha1_blob_ref {
	my $data_ref = shift;
	my $sha1 = Digest::SHA1->new;
	my $l = length($$data_ref);
	$sha1->add("blob $l\0");
	$sha1->add($$data_ref);
	return lc($sha1->hexdigest);
}

sub _p4_type_to_mode {
	my $p4_type = shift;
	($p4_type & P4_TYPE_EXEC ? 0100755 : 0100644);
}

sub show_files {
	my $dbh = shift;
	my $path = shift;
	my $change = shift;
	my $o = shift;

	my $output = $o->{output} ||= sub {
		my $row = shift;
		(my $relative = $row->{depotpath})
			=~ s{^\Q$path\E/?}{};
		if ( $o->{name_only} ) {
			print "$relative\n";
		}
		else {
			my ($l, $b);
			$b = $row->{blobid};
			if ( $o->{length} or
			     ($o->{blob} and !$row->{blobid}) ) {
				my $blob_data =
					get_rcs($row->{rcs_file},
						$row->{rcs_revision});
				if ( $o->{length} ) {
					$l = length $blob_data;
				}
				if ( $o->{blob} ) {
					# pass by ref only needed on
					# perl <5.8.1
					$b = sha1_blob_ref(\$blob_data);
				}
			}
			my $a = $o->{abbrev} || 40;
			# don't show trees yet
			printf( "%6o %s %s".($o->{length}?" %7d":"")
				."\t%s\n",
				_p4_type_to_mode($row->{file_type}),
				"blob",
				($o->{blob}
				 ? substr($b,0,$a)
				 : substr($row->{revision_md5},0,$a)),
				($o->{length} ? ($l) : ()),
				$relative);
		}
	};

	my (@where, @pl);

	push @where, "change = ?";
	push @pl, $change;

	if ( $o->{recurse} ) {
		push @where, 'depotpath like ?';
		push @pl, "$path/%";
	}
	else {
		push @where, 'depotpath ~ ?';
		push @pl, "$path(/[^/]*)?\$";
	}

	my $join_clause = "";
	if ($o->{blob} || $o->{marks}) {
		$join_clause = <<SQL;
	left join rev_marks
		using (depotpath, revision)
SQL
		if ($o->{blob}) {
			$join_clause .= <<SQL;
	left join marks
		using (mark)
SQL
		}
	}

	my $where = join " and ", @where;
	my $sth = $dbh->prepare(<<SQL);
select
	*
from
	change_state cs
$join_clause
where
	$where
order by
	depotpath asc
SQL
	$sth->execute(@pl);

	while ( my $row = $sth->fetchrow_hashref ) {
		$output->($row);
	}
}

sub index_for_version {
	my $dbh = shift;
	my $path = shift;
	my $change = shift;
	my %index;
	show_files($dbh, $path, $change,
		   { blob => 1,
		     recurse => 1,
		     output => sub {
			     my $row = shift;
			     (my $relative = $row->{depotpath})
				     =~ s{^\Q$path\E/?}{};

			     $index{$relative} =
				     [ $row->{revision_md5}, $row->{mark},
				       $row->{blobid}, $relative, $row->{last_change} ];
		     },
		   });
	return \%index;
}

sub index_eq {
	my $idx_a = shift;
	my $idx_b = shift;
	if ( !$idx_a and !$idx_b ) {
		return 1;
	}
	if ( !$idx_a or !$idx_b ) {
		if ( $VERBOSE > 1 ) {
			whisper "$idx_a->[3] in A, not B => not equal"
				if $idx_a;
			whisper "$idx_b->[3] in B, not A => not equal"
				if $idx_b;
		}
		return 0;
	}
	if ( $idx_a->[2] and $idx_b->[2] ) {
		if ( $VERBOSE > 1 ) {
			if ($idx_a->[2] ne $idx_b->[2]) {
				whisper "$idx_a->[3]: ".substr($idx_a->[2],0,12)
					." in A vs ".substr($idx_b->[2],0,12)
						." in B";
			} else {
				whisper "$idx_a->[3]: blob ID match";
			}
		}
		$idx_a->[2] eq $idx_b->[2];
	}
	elsif ( $idx_a->[1] and $idx_b->[1] and
		$idx_a->[1] == $idx_b->[1] ) {
		whisper "$idx_a->[3]: marknum match" if $VERBOSE > 1;
		return 1;
	}
	elsif ( $idx_a->[0] and $idx_b->[0] ) {
		if ( $VERBOSE > 1 ) {
			if ($idx_a->[0] ne $idx_b->[0]) {
				whisper "$idx_a->[3]: ".substr($idx_a->[0],0,7)
					." in A vs ".substr($idx_b->[0],0,7)
						." in B";
			} else {
				whisper "$idx_a->[3]: md5sum match";
			}
		}
		$idx_a->[0] eq $idx_b->[0];
	}
	else {
		no warnings 'uninitialized';
		moan "Can't compare index entries; (@$idx_a) vs (@$idx_b)";
		0;
	}
}

sub index_diff {
	my $base = shift;
	my $newer = shift;
	if ( !$base and $newer ) {
		return "added";
	}
	elsif ( $base and !$newer ) {
		return "deleted";
	}
	elsif ( index_eq($base, $newer) ) {
		return "unchanged";
	}
	else {
		return "changed";
	}
}

sub min_change {
	my $dbh = shift;
	my $o = shift;

	my $joins = "";
	my $having = "";

	if ( $o->{blobs} ) {
		$joins = <<SQL;
	left join rev r
		on (r.change = c.change and
			r.rev_change_type != 2)
	left join rev_marks rm
		using (depotpath, revision)
SQL
		$having = <<SQL;
having
	count(rm.mark)=0 and
	count(r.change)>0
SQL
	}
	elsif ( $o->{changes} ) {
		$joins = <<SQL;
	left join change_marks cm
		using (change)
SQL
		$having = <<SQL;
having
	count(cm.mark)=0 and
	count(c.change)>0
SQL
	}
	elsif ( $o->{branches} ) {
		$joins = <<SQL;
	left join change_branches cb
		using (change)
SQL
		$having = <<SQL;
having
	count(cb.branchpath)=0
SQL
	}
	elsif ( $o->{extant_branches} ) {
		$joins = <<SQL;
	join change_branches cb
		using (change)
SQL
	}
	elsif ( $o->{commits} ) {
		$joins = <<SQL;
	join change_branches cb
		on (cb.change = c.change)
	left join change_marks cm
		on (cb.branchpath = cm.branchpath and
			cb.change = cm.change)
SQL
		$having = <<SQL;
having
	count(cm.mark)=0 and
	count(c.change)>0
SQL
	}

	my $sql = <<SQL;
select
	c.change
from
	change c
${joins}
where
	closed = 1
group by
	c.change
${having}
order by
	c.change asc
limit 1
SQL

	mutter "finding first change with new "
		.($o->{blobs}?"blobs":"commits");
	my $change_sth = $dbh->prepare($sql);
	$change_sth->execute;
	my $min_change;
	$change_sth->bind_col(1, \$min_change);
	$change_sth->fetch;
	$change_sth->finish;

	return $min_change;
}

sub parse_export_opts {
	my $dbh = shift;
	my $type = shift;
	my %export_opts;
	{
		@ARGV = @_;
		my @gfi_options;
		getopt("n=i" => \$export_opts{chunk_size},
		       "depth=i" => \$export_opts{depth},
		       "l|long" => \$export_opts{long},
		       "recalc" => \$export_opts{derive_again},
		      );
		@_ = @ARGV;
	}
	if ( @_ ) {
		my $revspec = shift;
		if ( $revspec !~ m{^(\d+)(?:\.\.(\d+))?$} ) {
			abort "bad change spec '$revspec'";
		}
		@export_opts{qw(min max)} = ($1, $2);
	}
	if ( !$export_opts{min} ) {
		$export_opts{min} = min_change($dbh, { $type => 1 });
	}
	if ( $export_opts{min} and $export_opts{chunk_size} ) {
		$export_opts{max} = $export_opts{min}
			+ $export_opts{chunk_size} - 1;
	}
	if ( !$export_opts{max} ) {
		$export_opts{max} = max_change($dbh, { $type => 1 });
	}
	if ( $export_opts{min} and $export_opts{max} ) {
		$export_opts{chunk_size} = $export_opts{max}
			- $export_opts{min} + 1;
	}

	$export_opts{verbose} = $VERBOSE;
	%export_opts;
}

sub do_export_blobs {
	my $dbh = shift;

	my %export_opts = parse_export_opts($dbh, "blobs", @_);

	gfi_open(\%export_opts);

	export_blob_chunk($dbh, \%export_opts);
}

our $MARKS_FILE;

sub gfi_open {
	my $eo = shift;
	$MARKS_FILE ||= "p4raw.$$.marks";
	if ( -t STDOUT ) {
		open GFI, "|git fast-import --quiet "
			.($eo->{gfi_options}||"")
			.($eo->{depth}?"--depth=$eo->{depth} ":"")
			."--export-marks=$MARKS_FILE"
				or barf "popen gfi failed; $!";
	}
	else {
		open GFI, ">&STDOUT";
		open STDOUT, ">&STDERR";
		moan "won't be able to commit!";
		say "drop constraints on rev_marks / change_marks or "
			."this run will not be restartable";
		undef($MARKS_FILE);
	}
	binmode GFI;
}

use constant CHUNK_SIZE => 4096;

our $MARK_MIN;
our $MARK_MAX;
our $MARK;

sub gfi_get_marks {
	my $dbh = shift;
	my $count = shift;
	my ($dummy) = map { @$_ } @{ $dbh->selectall_arrayref(<<SQL) };
select nextval('gfi_mark')
SQL
	$dbh->do(<<SQL) or die $dbh->errstr;
alter sequence gfi_mark increment by $count
SQL
	($MARK_MAX) = map { @$_ } @{ $dbh->selectall_arrayref(<<SQL) };
select nextval('gfi_mark')
SQL
	$dbh->do(<<SQL) or die $dbh->errstr;
alter sequence gfi_mark increment by 1
SQL
	$MARK_MIN = $MARK_MAX - $count + 1;
	die "read nextval of $MARK_MAX" unless $MARK_MIN > 0;
	$MARK = $MARK_MIN - 1;
}

our %MARKS;
our %MARK_TYPES = qw(blob 1 commit 2 tag 3);

sub gfi_get_mark {
	my $dbh = shift;
	my $type = shift;
	unless ( $MARK_MAX and ++$MARK <= $MARK_MAX ) {
		($MARK) = map { @$_ } @{ $dbh->selectall_arrayref(<<SQL) };
select nextval('gfi_mark')
SQL
	}
	$MARKS{$MARK}=$MARK_TYPES{$type};
	$MARK;
}

sub gfi_send_blob {
	my $dbh = shift;
	my $buf = shift;
	my $mark = gfi_get_mark($dbh, "blob");
	print GFI "blob\n";
	print GFI "mark :", $mark, "\n";
	gfi_data($buf);
	$mark;
}

sub gfi_data {
	my $buf = shift;
	my $l = length($$buf);
	print GFI "data $l\n";
	print GFI $$buf, "\n";
}

sub gfi_start_commit {
	my $dbh = shift;
	my $mark = gfi_get_mark($dbh, "commit");
	my $ref = shift;
	my $author = shift;
	my $committer = shift;
	print GFI "commit ", $ref, "\n";
	print GFI "mark :", $mark, "\n";
	print GFI "author ", $author->[0], " <", $author->[1], "> ",
		$author->[2], "\n" if $author;
	print GFI "committer ", $committer->[0], " <", $committer->[1], "> ",
		$committer->[2], "\n";
	return $mark;
}

sub gfi_from {
	my $parent = shift;
	if ( defined $parent ) {
		print GFI "from ", $parent, "\n";
	}
	else {
		print GFI "deleteall\n";
	}
}

sub gfi_merge {
	while ( my $parent = shift ) {
		print GFI "merge ", $parent, "\n";
	}
}

sub gfi_filedelete {
	my $relname = shift;
	print GFI "D ", $relname, "\n";
}

sub gfi_filemodify {
	my $mode = shift;
	my $ref = shift;
	my $relname = shift;
	print GFI "M ", sprintf("%o", $mode), " ", $ref, " ", $relname, "\n";
}

sub gfi_finish_commit {
	print GFI "\n";
}

sub gfi_checkpoint {
	my $dbh = shift;

	if ( !defined $MARKS_FILE ) {
		moan "don't know where the marks are going!  hope you "
			.("dropped those rev_marks / change_marks "
			  ."constraints");
		goto commit;
	}

	if ( !keys %MARKS ) {
		moan "nothing to checkpoint";
		goto commit;
	}

	# send a dummy blob to make sure gfi writes marks out
	gfi_send_blob $dbh,
		\(join("", map { chr(rand(64)+33) } (1..3))
		  x rand(32) );

	my $last_mtime = (stat $MARKS_FILE)[9];
	say "Now checkpointing.";
	print GFI "checkpoint\n\n";
	GFI->flush();

	my $time;
	while ( ! -e $MARKS_FILE or
		$last_mtime and
		((stat _)[9] == $last_mtime) ) {
		sleep 1;
		$time++;
		say "waited ${time}s for $MARKS_FILE to be created";
	}

	my $insert_mark_sth = $dbh->prepare(<<SQL);
insert into marks
	(mark, commitid, blobid)
values
	(?, ?, ?)
SQL
	my $b_t = $MARK_TYPES{blob};
	my $c_t = $MARK_TYPES{commit};

	while ( keys %MARKS ) {
		my @marks = `cat $MARKS_FILE`;
		my ($t, $found, $mark, $sha1);
		for ( @marks ) {
			if (($mark, $sha1) =
			    m{^:(\d+) ([0-9a-f]{40})} and
			    ($t = delete $MARKS{$mark})
			   ) {
				$found++;
				$insert_mark_sth->execute
					($mark,
					 ($t == $c_t ? $sha1 : undef),
					 ($t == $b_t ? $sha1 : undef),
					);
			}
		}
		if ( $found ) {
			mutter "wrote $found marks to DB";
		}
		else {
			moan "still waiting for ".(scalar keys %MARKS)
				." mark(s) to appear";
			sleep 1;
		}
	}

 commit:
	$dbh->commit
		or moan "commit failed; ".$dbh->errstr;
}

sub export_blob_chunk {
	my $dbh = shift;
	my $o = shift;
	local($VERBOSE) = $o->{verbose};

	my $min_change = $o->{min};
	my $chunk_size = $o->{chunk_size};
	my $max_change = $o->{max};

	# psuedocode for blob import.
	# 1. find the lowest change which is yet to be marked as
	#    imported
	say "exporting blobs for changes $min_change .. "
		."$max_change";

	# 2. get all of the files in it
	$dbh->begin_work;
	my ($count_em_sth) = $dbh->prepare(<<SQL);
select
	count(distinct rev.depotpath),
	count(rev.revision)
from
	rev
	left join rev_marks
		using (depotpath, revision)
where
	rev.rev_change_type != 2 and
	rev_marks.mark is null and
	change between ? and ?
SQL
	$count_em_sth->execute($min_change, $min_change+$chunk_size-1);
	my ($paths, $revisions);
	$count_em_sth->bind_columns(\$paths, \$revisions);
	$count_em_sth->fetch;
	$count_em_sth->finish;
	mutter "this chunk touches $paths depot paths and $revisions"
		." distinct revisions";
	if ( !$revisions ) {
		say "no un-exported file revisions in this range";
		goto checkpoint;
	}

	# don't want to round-trip to the DB just to get sequence numbers
	# so do a special increment.  This is not transaction guarded!
	gfi_get_marks($dbh, $revisions);

	# 3. for each of those files, find all the ones without
	#    rev_blob rows
	my @files;

	# the sort method here could be improved further, but it is a
	# reasonable starting point and should mean that many
	# ancestrally related files are sent to fast-import in
	# sequence
	my $file_list = $dbh->prepare(<<SQL);
select
	rev.depotpath,
	rev.file_type,
	count(rev.revision) as num,
	min(rev.revision) as min,
	max(rev.revision) as max,
	integed.object,
	integed.object_minrev,
	integed.object_maxrev
from
	rev
	left join rev_marks
		using (depotpath, revision)
	left join integed
		on (int_type = 2 and subject = depotpath)
where
	rev.rev_change_type != 2 and
	rev_marks.mark is null and
	rev.change between ? and ?
group by
	depotpath,
	rev.file_type,
	integed.object,
	integed.object_minrev,
	integed.object_maxrev
order by
	(case when integed.object is null
		then depotpath
	else
		integed.object
	end),
	(case when integed.object is null
		then 0
	else
		1
	end);
SQL

	mutter "getting file list";
	$file_list->execute($min_change, $max_change);

	# 4. for each of those files, find *all* of the branched
	#    versions of it, and send them all at once to
	#    git-fast-import, entering rev_marks rows for them as we
	#    send marks to git-fast-import
	#    It's quite important to do all the revisions of a file at
	#    once, otherwise fast-import will not be able to make
	#    on-the-fly deltas and the repo will become gigabytes.
	#
	#    note "p4 print" is not required; can just use rcs
	#    directly by looking at the "rev" table; it has a rcs
	#    filename and revision that quite adequately refers to an
	#    rcs version.  So you can just collect
	#    `co -p1.2 -kb depot/mg.c` (eg), get its length, confirm
	#    the MD5, and then feed to git-fast-import using the
	#    "mark" functionality, perhaps marking it with the MD5
	#    or depotpath/revision.  Then when the fast-import
	#    "checkpoint" command is issued we will get back the
	#    GIT-SHA1 values.
	my $list_rcs_revs = $dbh->prepare(<<SQL);
select
	revision,
	rcs_file,
	rcs_revision,
	rev_change_type,
	revision_md5
from
	rev
	left join rev_marks rm
		using (depotpath, revision)
where
	rev_change_type != 2 and
	depotpath = ?	and
	rev.revision between ? and ? and
	rm.mark is null
SQL

	my $insert_rev_mark_row = $dbh->prepare(<<SQL);
insert into
	rev_marks (depotpath, revision, mark)
values
	(?, ?, ?)
SQL

	mutter "now exporting file images";
	my $tpb;
	if ( $o->{verbose} >= 0 ) {
		$tpb  = eval { Term::ProgressBar->new
				({ count => $revisions,
				   ETA => "linear",
				 }) };
	}
	my $done_revisions = 0;
	my $next_update = 1;
 	my $delete_md5 = '00000000000000000000000000000000';
	my %seen;
	my %md5_mark;
	while ( my $row = $file_list->fetchrow_hashref ) {

		my $depotpath = $row->{depotpath};
		$list_rcs_revs->execute(@{$row}{qw/depotpath min max/});
		$list_rcs_revs->bind_columns
			(\(my ($rev, $rcs_file, $rcs_revision,
			       $change_type, $md5)));

		while ( $list_rcs_revs->fetch ) {
			next if $seen{md5_hex("$depotpath#$rev")}++;

			my $has_md5 = $md5 ne $delete_md5;
			my $lc_md5 = lc($md5);
			my $mark;
			if ( $has_md5 and $md5_mark{$lc_md5} ) {
				$mark = $md5_mark{$lc_md5};
				goto record;
			}

			my $contents = get_rcs($rcs_file, $rcs_revision);

			my $found_md5;
			# don't do the md5 check on +k files
			if ( $has_md5 and
			     !($row->{file_type}&P4_TYPE_KORRUPT)
			   ) {
				$found_md5 = lc(md5_hex($contents));
				if ( $found_md5 ne $lc_md5 ) {
					# we fall over in a screaming heap
					die("MD5 mismatch on $depotpath"
					    ."#$rev ($rcs_file "
					    ."$rcs_revision); "
					    ."$found_md5 from co -p, "
					    ."$md5 in DB");
				}
			}

			$mark = gfi_send_blob($dbh, \$contents);
			$md5_mark{$lc_md5||$found_md5}
				= $mark if $has_md5 or $found_md5;
		record:
			eval {
				local($dbh->{PrintError}) = 0;
				$insert_rev_mark_row->execute
					($depotpath, $rev, $mark);
			};
			die "error inserting ($depotpath#$rev => $mark); $@"
				if $@;
			$done_revisions++;
		}
		if ( $tpb and $done_revisions >= $next_update ) {
			$next_update = $tpb->update($done_revisions);
		}
	}
	$tpb->update($done_revisions) if $tpb;
	$file_list->finish;

 checkpoint:
	unless ( $o->{no_checkpoint} ) {
		gfi_checkpoint($dbh);
	}
}

sub do_find_branches {
	my $dbh = shift;

	# "close enough" :)
	my %export_opts = parse_export_opts($dbh, "branches", @_);

	say "finding branches for $export_opts{chunk_size} changes";
	for my $change ( $export_opts{min} .. $export_opts{max} ) {
		$dbh->begin_work;
		change_stats($dbh, $change,
			     { compact => !$export_opts{long},
			       derive_again => $export_opts{derive_again},
			     },
			    );
		print "\n";
		$dbh->commit;
	}
}

sub check_branchpath {
	my $dbh = shift;
	my $branchpath = shift;
	my $change = shift;
	my $sth = $dbh->prepare(<<SQL.($change?<<SQL:""));
select
	max(change)
from
	change_branches
where
	branchpath = ?
SQL
and	change = ?
SQL
	$sth->execute($branchpath, ($change?($change):()));
	($change) = $sth->fetchrow_array;
	$change;
}

use Set::Object qw(set);

sub find_merge_base {
	my $dbh = shift;
	my @places = @_;

	my $max_change = max map { $_->[1] } @places;

	# slurp in change_parents
	my $sth = $dbh->prepare(<<SQL);
select
	*
from
	change_parents c
where
	change <= ? and
	(manual or (not manual and
		not exists (select true from change_parents c2
			where c2.change = c.change and c2.manual) and
		(c.none_unseen is null or c.none_unseen = true)))
SQL
	$sth->execute($max_change);
	my @cp;
	while ( my $row = $sth->fetchrow_hashref ) {
		push @cp, $row;
	}
	my %cp;
	for ( @cp ) {
		my $where = $_->{branchpath}."@".$_->{change};
		my $list = $cp{$where} ||= [];
		push @$list, $_;
	}

	# the merge base is the latest plane across the ancestry DAG
	# which is mergable from all the starting points.
	my @start = map { join '@', @$_ } @places;
	my %start = map { $_ => 1 } @start;
	whisper "finding merge base of: @start" if $VERBOSE > 1;
	my %parent_of = map { $_ => {$_=>1} } @start;
	my %stale;
	my %seen = map { $_ => 1 } @start;

	my $sortfunc = sub {
		my ($c_a) = ($_[0] =~ m{@(\d+)$});
		my ($c_b) = ($_[1] =~ m{@(\d+)$});
		($c_b <=> $c_a)
	};
	my @interesting = sort { $sortfunc->($a, $b) } keys %seen;
	my %bases;
	while ( grep { !exists $stale{$_} } @interesting and
		(my $item = shift @interesting) ) {

		my @parents;
		unless ( $item eq '@0' ) {
			@parents = map {
				$_->{parent_branchpath}."@".$_->{parent_change}
			} @{$cp{$item}};
			if ( !@parents ) {
				@parents = '@0';
			}
		}
		whisper "parents of $item are: @parents" if $VERBOSE > 1;
		if ( 0 and (grep { $start{$_} } @parents) >= (@start - 1) ) {
			# *THIS* is a merge base
			$bases{$item}++;
			for ( @parents ) {
				$stale{$_}++;
			}
		}

		my @parent_of;
		for my $tip ( @start ) {
			if ( $parent_of{$tip}{$item} ) {
				push @parent_of, $tip;
				for ( @parents ) {
					$parent_of{$tip}{$_}++;
				}
			}
		}
		if ( $stale{$item} ) {
			whisper "$item is stale" if $VERBOSE > 1;
			for ( @parents ) {
				$stale{$_}++;
			}
		}
		whisper "seen by branches: @parent_of" if $VERBOSE > 1;

		if ( @parent_of == @start ) {
			# merge base
			if ( !$stale{$item} ) {
				$bases{$item}++;
				whisper "making $item a merge base." if $VERBOSE > 1;
				for my $parent ( @parents ) {
					$stale{$parent}++;
				}
			}
			else {
				whisper "$item is a stale merge base."
					if $VERBOSE > 1;
			}
		}
		push @interesting,
			(grep { !$seen{$_}++ }
			 @parents);
		@interesting = sort { $sortfunc->($a, $b) }
			@interesting;

		$seen{$item}++;
	}

	return map { [ m{(.*)@(\d+)$} ] } keys %bases;
}

sub do_merge_base {
	my $dbh = shift;

	my @places;

	while ( my $item = shift ) {
		my ($branchpath, $change) =
			($item =~ m{^(//.*?)(?:\@(\d+))?$})
				or abort "expecting branch paths, not '$item'";

		$change = check_branchpath($dbh, $branchpath, $change)
			or barf "'$item' is not a valid branchpath";

		push @places, [ $branchpath, $change ];
	}

	my (@bases) = find_merge_base($dbh, @places);

	if ( @bases ) {
		say "merge base: ".join(", ", map { join '@', @$_ } @bases);
	}
	else {
		say "no valid merge base";
		exit 1;
	}
}

sub do_is_parent {
	my $dbh = shift;
}

	# 5. finally, we have rev_blob rows for all of the files
	#    in this version, so send a tree and/or commit object
	#    (though it might be easier to use
	#    `git update-index --index-info`).  Information from the
	#    integed table should probably go into the commit message,
	#    where it is not redundant (which is a difficult criterion
	#    to nail down for sure!)

sub export_commit_chunk {
	my $dbh = shift;
	my $o = shift;

	$dbh->begin_work() unless $dbh->ping == 3;

	# first, get a plan of branches to export
	my $commit_dag = row_iter($dbh, $o->{min}, $o->{max}, <<SQL);
select
	cb.branchpath,
	cb.change,
	cm2.mark as already,
	cp.parent_branchpath,
	cp.parent_change,
	cm.mark,
	m.commitid,
	cp.ref,
	cp.manual,
	cp.json_info
from
	change_branches cb
	left join change_marks cm2
		using (branchpath, change)
	left join change_parents cp
		on ( (cb.branchpath = cp.branchpath and
			cb.change = cp.change) and
			(cp.manual or (not cp.manual and
				not exists (select true from change_parents cp2
					where cp2.change = cp.change
						and cp2.manual) and
			(cp.none_unseen is null or cp.none_unseen = true)))
		)
	left join change_marks cm
		on (cp.parent_branchpath = cm.branchpath and
			cp.parent_change = cm.change)
	left join marks m
		on (m.mark = cm.mark)
where
	cb.change between ? and ?
order by
	cb.change,
	cb.branchpath,
	(cp.parent_branchpath = cb.branchpath) desc
SQL

	# a big query yes, but remember this is git-*fast*-import ;)
	my $files = row_iter($dbh, $o->{min}, $o->{max}, <<SQL);
select
	cb.change,
	cb.branchpath,
	substr(rev.depotpath, length(cb.branchpath)+2) as relpath,
	ct.title as change_type,
	file_type,
	mark,
	blobid
from
	change_branches cb
	join rev on (cb.change = rev.change
		and rev.depotpath like (cb.branchpath||'/%') )
	join change_type ct on (rev_change_type = change_type)
	left join rev_marks using (depotpath,revision)
	left join marks using (mark)
where
	cb.change between ? and ?
order by
	cb.change,
	cb.branchpath
SQL

	# remember which branches we have reset
	my %branches;
	my %cb_marks;
	my $to_ref = sub {
		my $x = shift;
		my $ref = $x->{ref} || $x->{commitid};
		if ( !$ref ) {
			my ($pb, $pc) =
				($x->{parent_branchpath},
				 $x->{parent_change});
			if ( $pb ) {
				my $mark = $x->{mark} || $cb_marks{$pb}{$pc};
				$ref = ":$mark";
			}
			else {
				$ref = undef;
			}
		}
		whisper "ref of parent: ".$ref
			if defined $ref;
		$ref;
	};

	my $desc_i = row_iter($dbh, $o->{min}, $o->{max}, <<SQL);
select
	change,
	realname,
	email,
	change_time,
	description
from
	change
	join p4user using (who_user)
	join change_desc using (change_desc_id)
where
	change between ? and ?
and	closed = 1
SQL

	my $insert_commit_mark_sth = $dbh->prepare(<<SQL);
insert into change_marks
	(branchpath, change, mark)
values
	(?, ?, ?)
SQL

	say "gathering export plan";
	$commit_dag->($commit_dag->());
	$files->($files->());

	say "exporting commits between $o->{min} and $o->{max}";
	my ($tpb, $next_update);
	if ( $o->{verbose} == 0 ) {
		$tpb  = eval { Term::ProgressBar->new
				({ count => $o->{chunk_size},
				   ETA => "linear",
				 }) };
	}
 change:
	while ( my $change_br = $commit_dag->() ) {

		my $change = $change_br->{change};
		my $bp = $change_br->{branchpath};
		my $ref = _path2ref($bp);
		if ( $change_br->{already} ) {
			mutter "skipping $bp\@$change - already marked";
			next;
		}
		mutter "exporting $bp\@$change to $ref";

		my @parents = $change_br;
		while ( 1 ) {
			my $x = $commit_dag->() or last;
			if ( $x->{branchpath} ne $bp or
			     $x->{change} != $change
			   ) {
				# put it back
				$commit_dag->($x);
				last;
			}
			push @parents, $x;
		}

		# fetch a change off
		my $desc;
		while ( !$desc or
			$desc->{change} < $change_br->{change} ) {
			$desc = $desc_i->() or do {
				moan "out of changes!  looking for"
					." $change_br->{change}";
				last change;
			};
		}
		# and put the change back!
		$desc_i->($desc);
		die "wrong change!"
			if $desc->{change} != $change_br->{change};

		my ($author, $committer, $description)
			= make_commit($desc, @parents);

		if ( $VERBOSE > 0 and $o->{long} ) {
			print "author: @$author\n" if $author;
			print "committer: @$committer\n";
			print "$description\n";
		}

		# write a description
		my $mark = gfi_start_commit
			($dbh, $ref, $author, $committer);
		$cb_marks{$bp}{$change} = $mark;
		gfi_data(\$description);
		$insert_commit_mark_sth->execute($bp, $change, $mark);

		# write out the parents
		my $n = 0;
		my $from = shift @parents;
		if ( $from->{branchpath} ne $bp or !$branches{$bp}
		     or $branches{$bp} != $from->{parent_change}
		   ) {
			my $where = $to_ref->($from);
			whisper "sending 'from' of $where"
				if $where;
			gfi_from($where);
		}
		if (@parents) {
			mutter @parents." extra merge parents";
			$DB::single = 1;
			gfi_merge(map { $to_ref->($_) } @parents);
		}

		# now, get all the files in that revision and send
		# them to gfi
		while ( my $rev = $files->() ) {
			if ( $rev->{change} != $change_br->{change} or
			     $rev->{branchpath} ne $change_br->{branchpath}
			   ) {
				$files->($rev);
				last;
			}

			if ( $rev->{change_type} eq "delete" ) {
				if ( $VERBOSE > 0 and $o->{long} ) {
					print "... D $rev->{relpath}\n";
				}
				gfi_filedelete($rev->{relpath});
			}
			else {
				my $ft = $rev->{file_type};
				my $mode = _p4_type_to_mode($ft);
				if ( !$rev->{blobid} and
				     !$rev->{mark} ) {
					say "error: no mark/blob for $rev->{branchpath}\@$rev->{change}:$rev->{relpath}";
					say "Aborting change export.";
					last change;
				}
				my $dataref = $rev->{blobid} ||
					":".$rev->{mark};
				my $relpath =$rev->{relpath};
				if ( $VERBOSE > 0 and $o->{long} ) {
					print "... M $rev->{relpath}\n";
				}
				gfi_filemodify ($mode, $dataref, $relpath);
			}
		}
		gfi_finish_commit;

		my $done_revisions =
			($o->{chunk_size} - ($o->{max} - $change));
		if ( $tpb and
		     ( not $next_update or
		       $done_revisions >= $next_update ) ) {
			$next_update = $tpb->update($done_revisions);
		}
	}
	$tpb->update($o->{chunk_size}) if $tpb;

	unless ( $o->{no_checkpoint} ) {
		gfi_checkpoint($dbh);
	}
}

sub make_commit {
	my $desc = shift;
	my @parents = @_;

	my $author = undef;
	my $committer = [ $desc->{realname}, $desc->{email},
			  $desc->{change_time}." +0000" ];

	my $description = $desc->{description};

	# some perl-specific conventions
	my @authors;

	my $branchpath = $parents[0]{branchpath};
	my $change = $parents[0]{change};

	$description =~ s{\s*\Z}{\n};
	$description .= "\np4raw-id: $branchpath\@$change";

	my @notes;
	my $last;
	for my $p ( @parents ) {
		if ( $p->{json_info} and
		     (!$last or $p->{json_info} ne $last)) {
			$last = $p->{json_info};
			my $oj = jsonToObj($p->{json_info});
			push @notes, show_juice($p, $oj);
		}
	}

	$author, $committer,
		join("\n", $description, map { wrap("", "\t", $_) }
		     @notes);
}

sub show_juice {
	my $parent = shift;
	my $oj = shift;
	my @glass;
	if ( $oj->{omitted} and @{$oj->{omitted}} ) {
		push @glass, join(" ", "p4raw-omitted:",
				  sort @{ $oj->{omitted} });
	}
	if ( $oj->{curious} and @{$oj->{curious}} ) {
		push @glass, join(" ", "p4raw-curious:",
				  sort @{ $oj->{curious} });
	}
	if ( $oj->{integrated} ) {
		while ( my ($source_path, $revcx)
			= each %{$oj->{integrated} }) {
			my %idx;
			for my $relpath ( sort keys %$revcx ) {
				my $x = $revcx->{$relpath};
				my $hr = $x->{int_subj_headrev};
				my $max = $x->{int_subj_max_change};
				$max = $parent->{parent_change} if $hr;
				my $min = $x->{int_subj_min_change};
				my $ct = $x->{change_title};
				my $it = $x->{int_obj_title};
				push @{ $idx{$max}{$ct}{$it} ||= [] },
					[$min,$relpath];
			}
			my @src_revs = sort { $b<=>$a } keys %idx;
			for my $rev ( @src_revs ) {
				my %ctidx = %{$idx{$rev}};
				for my $ct ( sort keys %ctidx ) {
					my %i = %{$ctidx{$ct}};
					(my $past = $ct) =~ s{e?$}{ed};
					push @glass,
						join(" ", "p4raw-$past:",
						     "from $source_path\@$rev",
						     map {
							   my $i = $i{$_};
							   my $last;
							   s{(?:to| from|d by)$}{};
							   my @rv;
							   push @rv, "'$_'";
							   for my $f (sort { ($a->[0]||0)<=>($b->[0]||0) or
										     $a->[1] cmp $b->[1] }
								      @$i ) {
								   if ( !$last or $last != $f->[0] ) {
									   if ( $last ) {
										   push @rv, "(\@$last..)";
									   }
								   }
								   push @rv, $f->[1];
								   $last = $f->[0];
							   }
							   if ( $last ) {
								   push @rv, "(\@$last..)";
							   }
							   @rv
						   } sort keys %i);
				}
			}
		}
	}
	@glass;
}

sub do_export_commits {
	my $dbh = shift;

	my %export_opts = parse_export_opts($dbh, "commits", @_);

	gfi_open(\%export_opts);

	export_commit_chunk($dbh, \%export_opts);
}

sub do_unexport_commits {
	my $dbh = shift;

	my %export_opts = parse_export_opts($dbh, "commits", @_);

	say "deleting commit records for $export_opts{chunk_size} changes";
	$dbh->do("delete from change_marks where change between ? and ?",
		 undef,
		 $export_opts{min},
		 $export_opts{max});
	my $branches = change_branches_iter($dbh, $export_opts{min}-1, "max");
	while ( my $br = $branches->() ) {
		my $ref = _path2ref($br->{branchpath});
		
	}
}

sub do_export {
	my $dbh = shift;

	my %export_opts = parse_export_opts($dbh, "commits", @_);

	gfi_open(\%export_opts);

	$export_opts{no_checkpoint} = 1;
	export_blob_chunk($dbh, \%export_opts);

	for my $change ( $export_opts{min} .. $export_opts{max} ) {
		change_stats($dbh, $change,
			     { compact => !$export_opts{long},
			     },
			    );
		print "\n";
	}

	delete $export_opts{no_checkpoint};
	export_commit_chunk($dbh, \%export_opts);

}

our $PREFIX = $ENV{GIT_P4RAW_PREFIX} || "p4";

sub _path2ref {
        my $branchpath = shift;
        $branchpath =~ s{^//(?:depot/)?}{$PREFIX/};
        #$branchpath =~ s{/}{/}g;
        "refs/heads/$branchpath";
}

sub do_dump {
	my $dbh = shift;

	my $journal;
	for ( my $i = 1;
	      -e ($journal = "p4raw-journal-$i.asv.gz");
	      $i++ ) { }

	say "creating new journal file $journal";
	open JOURNAL, "|-", "gzip > $journal";
	my $total;
	for my $table ( qw( change_branches marks rev_marks
			    change_marks change_parents ) ) {

		$dbh->begin_work;
		my $is_cp = $table eq "change_parents";
		my $sth = $dbh->prepare(<<SQL.($is_cp?<<SQL:""));
select * from $table
where source_file = 'new'
SQL
and (manual or (not manual and
     not exists (select true from change_parents cp2
	         where cp2.change = change_parents.change
		   and cp2.manual)))
SQL
		mutter "dumping $table";
		$sth->execute;
		my $c = 0;
		while ( my @data = $sth->fetchrow_array ) {
			$c++;
			$total++;
			shift @data;
			print JOURNAL _to_p4_journal_format $table,
				@data;
		}
		mutter "mutter updating $table";
		$dbh->do(<<SQL);
update $table
set source_file = '$journal'
where source_file = 'new'
SQL
		mutter "commit";
		$dbh->commit;
		say "dumped $c rows from $table";
	}
	close JOURNAL;
	if ( !$total ) {
		say "removing $journal - no content";
		unlink($journal);
	}

}

sub do_graft {
	my $dbh = shift;
	my %graft_opts;
	{
		@ARGV = @_;
		my @gfi_options;
		getopt("a" => \$graft_opts{add},
		       "d=i" => \$graft_opts{delete},
		      );
		@_ = @ARGV;
	}
	abort "bogus extra arguments: @_"
		if @_ and $graft_opts{delete};
	$dbh->begin_work;
	if ( $graft_opts{delete} or !$graft_opts{add} ) {
		$dbh->do(<<SQL);
delete from change_parents
where manual
SQL
	}
	my ($change, @parents);
	my $c2bpc = sub {
		my $change = shift;
		my $cbi = change_branches_iter($dbh, $change, "eq");
		my $row = $cbi->()
			or barf "no depotpaths for change $change";
		abort "multiple branches matched by spec $change"
			if $cbi->();
		($row->{branchpath}, $row->{change});
	};
	my @places;
	while ( my $change = shift ) {
		if ( $change =~ m{^(//.+)@(\d+)$} ) {
			$change = [$1,$2];
		}
		elsif ( $change =~ m{^\d+$} ) {
			$change = [$c2bpc->($change)];
		}
		else {
			my ($rc, $ref) =
				capture_err qw(git rev-parse), $change;
			if ( $rc ) {
				barf "bad change/ref '$ref'";
			}
			chomp($ref);
		}
		push @places, $change;
	}
	if ( @places == 1 ) {
		abort "bad number of arguments to graft";
	}
	elsif ( @places ) {
		my $top = shift @places;
		if ( !ref $top ) {
			abort "can't graft onto git ref '$top' - only "
				."branchpaths"
		}
		for my $graft ( @places ) {
			if ( ref $graft ) {
				$dbh->do(<<SQL,undef,@$top,@$graft);
insert into change_parents
	(branchpath, change, parent_branchpath, parent_change)
values
	(?, ?, ?, ?)
SQL
			}
			else {
				$dbh->do(<<SQL,undef,@$top,$graft);
insert into change_parents
	(branchpath, change, ref)
values
	(?, ?, ?)
SQL
			}
		}
	}
	$dbh->commit;
}

#=====================================================================
#  MAIN SECTION STARTS HERE
#=====================================================================
getopt("script|s" => \$SCRIPT_MODE,
       "prefix=s" => \$PREFIX,
      );
if (! -t STDOUT) {
	$SCRIPT_MODE = 1;
}

binmode STDOUT, ":utf8";

my $action = shift;
abort "no action given" unless $action;
$action =~ s{-}{_}g;
abort "bad action/argument `$action'" unless defined &{"do_$action"};

my $dbh = DBI->connect("dbi:Pg:") or barf "DBI connect failed";
$dbh->{RaiseError}=1;
$dbh->{PrintError}=1;
$dbh->{AutoCommit}=1;

&{"do_$action"}($dbh, @ARGV);

__END__

=head1 NAME

git-p4raw - git fast-import exporter for RAW perforce repositories

=head1 SYNOPSIS

 # import commands:
 git-p4raw init     # to return here: git-p4raw drop
 git-p4raw load
 git-p4raw check
 git-p4raw find-branches            # detect branches
 git-p4raw graft CHANGE commit-ish  # configure manual reparenting
 git-p4raw export                   # detect branches
 git-p4raw dump                     # save information for others

 # query commands:
 git-p4raw { find-change N | describe N | integrated DEPOTPATH
           | filelog DEPOTPATH | changes [ -l ] [ file[#range] ]
           | annotate PATH }

=head1 DESCRIPTION

B<git-p4raw> is a tool for importing perforce repositories into git,
and querying the legacy metadata in perpetuity.

It assumes you have the raw Perforce repository lying around, and does
not require the perforce server.  All you need are the C<checkpoint>,
C<journal> and RCS files.  If you want to specify things like where
the target git repository is, or which Postgres database to use, this
is configured in the normal way with environment variables
(C<GIT_DIR>, C<PGDATABASE>, etc).

=head1 COMMAND LINE OPTIONS

=over

=item B<-s, --script>

Instead of printing human-readable output, print something easily
parsable.  Automatically selected if standard output is not a terminal.

=item B<-h, --help>

Display a program usage screen and exit.

=item B<-V, --version>

Display program version and exit.

=item B<-v, --verbose>

Verbose command execution, displaying things like the
commands run, their output, etc.

=item B<-q, --quiet>

Suppress all normal program output; only display errors and
warnings.

=item B<-d, --debug>

Display output to help someone debug this script, not the
process going on.

=back

=head1 COMMANDS

=head2 IMPORT OPERATION

=over

=item C<git-p4raw init>

The first command, C<init>, initialises the database tables and git
repository.

=item C<git-p4raw drop>

C<drop> can be used to drop all database tables and destroy the git
repository, in a somewhat molly-guarded fashion.

=item C<git-p4raw load [-r] [-f] [filename...]>

The second command, C<load>, loads all of the Perforce data from the
C<checkpoint.NNN.gz> and C<journal> files which it expects to find in
the current directory (the root of the Perforce import).  You can
optionally specify which files to load from.

If you specify the C<-r> option, then the load will happen to
temporary tables first, with new data merged in at the end using
joins.  The merge rule is oldest-wins.  Without this option, the data
is blindly inserted.

If you specify C<-f>, then the normal logic that tries to prevent
datafiles from being loaded twice is skipped.

B<ERRATA>: currently you will need to manually load the FIRST journal
with:

  git-p4raw load -r -f journal.123.gz

Where 123 is the highest number checkpoint you have.

=item C<git-p4raw check>

This third command, C<check>, adds constraints to the database schema
and looks for errant data conditions.

If any of these constraints fail, and don't prompt to correct the data
to your satisfaction, you should investigate what is going on and
correct the data before proceeding.  The code makes assumptions that
these constraints hold.

When the command asks questions, the answers will be written to a file
called C<p4raw-extra-x.asv> in the Perforce checkpoint format (and
automatically re-loaded if you run C<load> again without arguments).

(TODO - some inconsistencies such as missing integration records are
not dealt with, and may require manual patching or use of the C<graft>
command, below)

=item C<git-p4raw graft { -d change | [ -a ] change change ... }> (TODO)

The C<graft> command is optional, and is principally for those who
want to override the decisions that this tool makes (and modifies what
is shown ahead of time using the C<describe> sub-command, see below).

When grafts are specified, they I<replace> the detected parents
completely.  Use C<-a> to add to the detected/already configured
parents.

You can specify just a change number, in which case the (presumably
only) branch effected in that change will be specified.  You should
have already run find-branches to do that.

Disambiguate by prefixing the change with the branch path:

   git-p4raw -a //depot/perl@18 //depot/ansiperl@17

This would say that the branch at C<//depot/ansiperl> change 17 should
be added to the parents of C<//depot/perl> change 18.

If a "change" parses as a git commit ID via C<git rev-parse>, it is
treated as external to the data being imported.  Do B<not> use commit
IDs or references from previous import runs here!

The C<-d> option will reset existing grafts for a change by deleting
all the manual ones.

Note: use B<git-p4raw dump> to save the grafts you make to journal
files so that they can be reloaded later on if you choose to.

For example, this was the initial graft for Perl's Perforce
repository:

  git-p4raw graft 1 perl-5.003

An example interactive session:

  maia:~/src/p4-rsync$ git-p4raw describe 17
  Change 17 by mbeattie@localhost on 1997/05/25 06:46:49
  
          Wholesale update to 5.004.
  
  On path //depot/relperl,
          add 291 file(s)
          delete 27 file(s)
          edit 392 file(s)
  
  Parent: //depot/relperl@16
  maia:~/src/p4-rsync$ git-p4raw graft 17 16 perl-5.004
  maia:~/src/p4-rsync$ git-p4raw describe 17
  Change 17 by mbeattie@localhost on 1997/05/25 06:46:49
  
          Wholesale update to 5.004.
  
  On path //depot/relperl,
          add 291 file(s)
          delete 27 file(s)
          edit 392 file(s)
  
  Parent: //depot/relperl@16 (manual)
  Parent: perl-5.004
  maia:~/src/p4-rsync$ git-p4raw export-commits -v 2..17
  git-p4raw: gathering export plan
  git-p4raw: exporting commits between 2 and 17
  git-p4raw: exporting //depot/perl@2 to refs/heads/p4/depot/perl
  git-p4raw: exporting //depot/thrperl@3 to refs/heads/p4/depot/thrperl
  git-p4raw: exporting //depot/thrperl@4 to refs/heads/p4/depot/thrperl
  git-p4raw: exporting //depot/thrperl@5 to refs/heads/p4/depot/thrperl
  git-p4raw: exporting //depot/perlext/Thread@6 to refs/heads/p4/depot/perlext/Thread
  git-p4raw: exporting //depot/perlext/Thread@7 to refs/heads/p4/depot/perlext/Thread
  git-p4raw: exporting //depot/thrperl@8 to refs/heads/p4/depot/thrperl
  git-p4raw: exporting //depot/thrperl@9 to refs/heads/p4/depot/thrperl
  git-p4raw: exporting //depot/perlext/Compiler@10 to refs/heads/p4/depot/perlext/Compiler
  git-p4raw: exporting //depot/perlext/Compiler@11 to refs/heads/p4/depot/perlext/Compiler
  git-p4raw: exporting //depot/perlext/Compiler@12 to refs/heads/p4/depot/perlext/Compiler
  git-p4raw: exporting //depot/perlext/Compiler@13 to refs/heads/p4/depot/perlext/Compiler
  git-p4raw: exporting //depot/perlext/Compiler@14 to refs/heads/p4/depot/perlext/Compiler
  git-p4raw: exporting //depot/relperl@16 to refs/heads/p4/depot/relperl
  git-p4raw: exporting //depot/relperl@17 to refs/heads/p4/depot/relperl
  git-p4raw: 1 extra merge parents
  git-p4raw: Now checkpointing.
  git-p4raw: waited 1s for p4raw.21152.marks to be created
  git-p4raw: wrote 16 marks to DB

=cut

=item C<git-p4raw export [ CHG[..CHG] | -n NUM ]>

=item C<git-p4raw export-blobs [ CHG[..CHG] | -n NUM ]>

=item C<git-p4raw export-commits [ CHG[..CHG] | -n NUM ]>

Export a bunch of changes (or, just the blobs, or just the commits)
bounded by a range of revisions or the next NUM revisions, to a C<git
fast-import> process.  If this command is started with standard output
as a terminal, it will start C<git fast-import> itself.

If you start C<git fast-import>, you must take care to pass
C<--export-marks> to it if you want to perform subsequent import runs.
Also you will need to remove the foreign key constraints on rev_marks
and change_marks.

=head3 export common options

=over

=item C<-n=INT>

Size of a "chunk" for export.

=item C<--depth=N>

Specify the delta depth.  If you are working on projects with a long
history this can save a lot of space.  Good for archives of old history.

=item  

=back

=back

=head2 INFORMATIONAL COMMANDS

These other commands are also mostly implemented, to show information
from the database.  Many of these commands closely correspond to their
C<p4> counterparts, though some are unique to this tool.

=over

=item C<git-p4raw find-change N>

(post-conversion) Just show the mapped git commits for a change
number.  There may be more than one if the change affected multiple
branches.  This command will be modelled on C<git-svn find-rev>, so
also be capable of showing the Perforce change number from a git
commit ID.  Currently this only looks at information in the database.

=item C<git-p4raw describe N>

Show change N vital statistics (TODO: post-conversion, mapped git
commits), and the files that were modified in that change.  A bit like
C<p4 describe -s> or C<git show --stat>.

This command performs a fairly mammoth query to determine whether
changes with lots of "integrate" changes look enough like a
cross-merge to be represented as such.  This works by looking at the
revisions of the source paths for 'integrate' changes, and then
finding out if any of those paths have new revisions between the one
that was 'integrated' and the change number in question.  It then
lists the change numbers that the revisions being integrated came
from, or "HEAD" if that was the most recent revision on that branch at
that time.  Thus, if you see output like this:

 On path //depot/perl,
         delete from //depot/relperl (HEAD), 27 file(s)
         branch from //depot/relperl (HEAD), 291 file(s)
         integrate from //depot/relperl (HEAD), 392 file(s)

Then the integration information does not contradict the assertion
that the change in question is a cross-merge from F<//depot/relperl>
to F<//depot/perl>.

However, this is not yet quite enough to prove that the integration
information in the change is a cross-merge; we also need to show that
there are changes between the I<merge base> of the two branches that
could have been merged, but are not mentioned.  So, if there are any
merge candidates they are all inspected to see if there are any files
which were not merged.  The results are totalled up and displayed.  If
you add C<-w> to the C<describe> command, then it will save the
information in the C<grafts> table.

=item C<git-p4raw find-branches [STARTREV[..REV]]>

Scan the changes from STARTREV to REV and try to find branches.

This command is equivalent to running C<git-p4raw describe N -w>
successively for each change.

=item C<git-p4raw integrated DEPOTPATH>

Mimic the 'p4 integrated' command precisely, from the database
information.

With git you'd probably use something like C<gitk --all -- filename>
to show all changes that touched a particular file and their relative
ancestry.

=item C<git-p4raw filelog DEPOTPATH>

Mimic the 'p4 filelog' command precisely, from the database
information.

Again, you'd probably just use the C<gitk> file selector or perhaps
even C<git log> with the same options to show this information.  The
principle difference being you won't see things like C<copy into>,
C<branch into>, etc - only the C<from> relationships.

=item C<git-p4raw changes [ -m NUM | -l ] [ file[revRange] ]>

Mimic the 'p4 changes' command closely from the database information.

C<-m NUM> is like C<git log -NUM>, and the C<-l> is like dropping the
C<--pretty=oneline> from the concise C<git-log --pretty=oneline>
command (see also L<git-config/alias.*>).  C<git-log> also supports
adding C<file>, but the C<revRange> thing is a perforce-ism not
carried over.

The C<-i> option is basically implied by C<git-log>, so long as the
"integrate" node was a branch cross-merge.  For cherry picking, the
equivalent command will be something like C<git-log --left-right
--cherry-pick otherbranch...HEAD -- filename>, and won't see cases
where the change was picked from another change with modifications.
However, there I<will> be a note in the changelog that the file was
picked when using C<git-log>, and as a last resort there is always
this command.

=item C<git-p4raw print [ -c CHANGE ] [ -Q ] [ -a ] file[rev]>

Prints the contents of a Perforce file at a particular revision.
C<-q> is a standard Scriptalicious switch, so suppress the header with
C<-Q>.

Currently this command does not vary its output like C<p4 print> does
based on the filetype, to add trailing linefeeds and the like, perform
CR/LF conversion or keyword expansion.

You can print all versions of the file with C<-a> as in Perforce, but
revision selectors are still TODO.

Specify a change number with C<-c NUM>.

=item C<git-p4raw ls-tree branch[@CHANGE]>

Show the contents of a particular Perforce path at particular
change.  Defaults to the latest change.

=item C<git-p4raw merge-base branch[@CHANGE] branch[@CHANGE] [...]>

Find the merge base of the passed changes.  Returns a list of change
paths and change numbers.

The returned list (hopefully) has the following properties:

=over

=item *

Every one of the passed branches are descended from all of the
returned bases.

=item *

None of the passed branches have any parents which are not descended
from or a parent of one of the returned changes.

=item *

There are no other lists which satisfy the above properties, where one
or more of the items of the list is a descendent of one of the
returned items, B<and> all of the other items are descended from it.

=back

=item C<git-p4raw show-branches [CHANGE]>

Show the list of branches (if the option is passed, as they were at
the given change)

=item C<git-p4raw annotate file[revRange]> (TODO)

Run C<git annotate> on the final result for the equivalent of this.
However, this command will print the (head) revisions for the given
depotpath which C<git annotate> would not normally search; this
information could be used with C<git annotate --incremental> to
produce the same results as C<p4 annotate>.

That problem goes away in practice with a changeset-based development
style, so this is mostly for getting the best annotation possible for
the current Perforce changes.

=back

As this program is not currently envisioned to support committing back
to Perforce, these commands will never be implemented, but details on
how the same thing is achieved with git follows;

=over

=item C<p4 sync>

This is something like C<git pull>, which is a C<git fetch> and a
C<git merge> in one.  However, in git you should always commit (or
stash) local changes first.

C<p4 sync -f> is very much like C<git merge -s theirs>, similarly
C<p4 sync -k> is like C<git merge -s ours>

The C<-n> option, well with git you normally just stash your changes
somewhere safe, merge and see what happens.  If you don't like it you
can C<git reset> back to where you were.  But if you like, the
plumbing command C<git read-tree -m> with a temporary "index" (read
the man page) can be used to do exactly the same thing (say, in a
script).

=item C<p4 opened>

This is very similar to the git 1.5.3+ command C<git stash list>
followed by C<git stash show>.  Or the alternate porcelain system
called "stacked git".

=item C<p4 edit>

With C<git add> you mark a file (in its current state) as belonging to
the commit/change that you are working on.  Saving files as belonging
to a particular stashed change can be done by stashing it with a new
name, pulling out the old stash and cherry picking the new stash on
top.  This is certainly one area where stacked git (currently)
provides much better command set, if less integration with
hunk-picking tools like "git gui".

=item C<p4 diff>

C<-du> is the default to C<git diff>.  You'll have to translate the
arguments to diff using the C<describe> or C<find-change>

=item C<p4 submit>

The command is C<git push>.  Assuming you have access (or maybe you're
pushing to an open access/mob branch), you can push any upstream
branch forward that has its HEAD commit in your ancestry.  So,
atomicity is enforced in that manner - if someone else pushes first,
you need to merge their commit in before pushing yours.  However you
can always push to a new branch.

Creating a new branch is not an issue; the names are considered
temporary pointers which can safely be discarded if the revision is
merged, or even thrown into a non-default ref space such as
C<refs/Attic/...> (sick sense of humour, I know) so that they don't
clutter, should the change be considered not worth preserving, or
should it get fixed up into a better change.  It can even get deleted.

=item C<p4v>

Currently the major git UIs are C<git gui> (for making commits, or
amending the last commit) and C<gitk> (for viewing/searching the
commit graph, inspecting commits, and some limited amount of changes
like cherry picking).

=back

=cut

# Local Variables:
#   mode: cperl
#   cperl-brace-offset: 0
#   cperl-continued-brace-offset: 0
#   cperl-indent-level: 8
#   cperl-label-offset: -8
#   cperl-merge-trailing-else: nil
#   cperl-continued-statement-offset: 8
# End:

=head1 OTHER FIX-UPS

=head2 Correcting branch decisions

If the decision made by C<describe> is awfully wrong, consider
inserting some rows manually.

  maia:~/src/p4-rsync$ git-p4raw describe 3736
  Change 3736 by jhi@alpha on 1999/07/26 01:10:03
  
          Populate metaconfig branch.
  
  git-p4raw: warning: ignoring changes on path //depot/metaconfig/U/ebcdic@3736
  git-p4raw: warning: ignoring changes on path //depot/metaconfig/U/a_dvisory@3736
  git-p4raw: warning: ignoring changes on path //depot/metaconfig/U/acl@3736
  git-p4raw: warning: ignoring changes on path //depot/metaconfig/U/compline@3736
  On path //depot/metaconfig/U,
          add 353 file(s)
  
  On path //depot/metaconfig/U.check,
          add 7 file(s)
  
  On path //depot/metaconfig/dist-3.0at70,
          add 576 file(s)
  
  On path //depot/metaconfig/dist-3.0at70b,
          add 633 file(s)
  
  maia:~/src/p4-rsync$ psql
  Welcome to psql 8.2.4, the PostgreSQL interactive terminal.
  
  Type:  \copyright for distribution terms
         \h for help with SQL commands
         \? for help with psql commands
         \g or terminate with semicolon to execute query
         \q to quit
  
  pumpkin=# delete from change_parents
            where parent_branchpath like '//depot/metaconfig/%';
  DELETE 690 0
  pumpkin=# delete from change_branches
            where branchpath like '//depot/metaconfig/%';
  DELETE 694 0
  pumpkin=# delete from change_branches where change = 3736;
  DELETE 4
  pumpkin=# insert into change_branches (branchpath, change)
     values ('//depot/metaconfig', 3736);
  INSERT 0 1
  pumpkin=# \q
  maia:~/src/p4-rsync$ git-p4raw describe 3736 -w
  Change 3736 by jhi@alpha on 1999/07/26 01:10:03
  
          Populate metaconfig branch.
  
  On path //depot/metaconfig,
          add 1569 file(s)
  
  maia:~/src/p4-rsync$ 

=head2 Replacing Perforce changes with previously crafted ones

An alternative to grafting is to replace commits entirely.  To do
this, insert into the change_marks and marks tables.

  begin transaction;
  insert into change_marks (branchpath, change, mark)
  values ('//depot/blah', 1234, nextval('gfi_mark'));
  insert into marks (mark, commitid)
  values (currval('gfi_mark'),
  '1234567890123456789012345678901234567890');
  commit;

This is useful for grafting the first change on from any pre-perforce
archaeological remains that your project might have.

